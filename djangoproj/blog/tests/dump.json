[{"slug": "pycon-2016-personal-impression", "title": "PyCon PL 2016: Personal Impression", "text": "Three weeks ago, I together with two other TEONITE developers took part in PyCon PL 2016 , a Polish conference obviously dedicated to everything Python-related. Today, three weeks after the conference, I decided to write a bit about my PyCon PL impression and present some conclusion I came with.  Favorite talks and topics  Naturally, there were some very interesting talks as well as those less interesting, at least for me. Of course, all of them were about Python usage or related to Python, like Colorful deployments by Maciej Szulik in which he talked about continuous delivery and some strategies of deployment and presented them on the Python-written project example.  In the retrospect, one of the better talks was Nicholas Tollervey\u2019s Python in Education . He talked about the UK\u2019s Python community and its role in UK\u2019s economic, political and educational landscape. He also presented the Micro Bit (stylized as micro:bit) which is a ARM-based embedded system developed for educational purposes by BBC. Packed with  ARM Cortex-M0 processor, accelerometer and magnetometer, USB port, Bluetooth connectivity, 25 LEDs and two programmable buttons gives quite a number of applications and use cases. Generally, a great tool to learn programming. Nicholas Tollervey also talked about how the micro:bit is used by 11-12 years olds in schools to learn basics of the programming by using simplified Python - MicroPython. Personally, I think that this is a great way to interest children in programming basics and familiarize them with fundamental practices and way of thinking.  One of the topic I\u2019m very much into is machine learning and everything related to it. Thus, I went on the talk about building foundation for Ukrainian NLP (Natural Language Processing). Generally, our Eastern neighbors scraped a ton of Ukrainian websites and treated the data with some deep learning magic. For me, important conclusion was that there is a smaller number of tools for languages other than English, so it's harder to work with languages like Ukrainian or to work on Polish language, we would need to also do some major scraping. And I mean MAJOR.  I also like the idea of lightning talks. Time limit of 5 minutes forced people to cut the claptrap and talk only about juicy, important parts without going into unnecessary details. Of course, if you wanted some details, you could just go and ask the speaker off-stage.  Target audience  Without boasting (Ok, maybe just a bit.) I can honestly say that all three of us are experienced developers that know Python, its capabilities and use cases very well. Maybe, that\u2019s why we didn\u2019t learn as much from some of the talks. For example, I was counting that talk titled Machine learning - how to solve complex problems (original title: Uczenie maszynowe - czyli jak rozwi\u0105zywa\u0107 nietrywialne problemy ) will be about application of machine learning methods to solve really complex and significant problems from different fields of expertise. In practice, it was a list of various Python libraries for machine learning and data science like scikit-learn or PyBrain used by the speaker in his biology research. Not very interesting for developers working in enterprise or web. Likewise, Artur Czepiel\u2019s Evolution of \"Best Practices\" in Django was all about very basic Django stuff and definitions.  Now, don\u2019t get me wrong. I don\u2019t want to say that the talks itself were bad, or that presenting Python basics is bad. On the contrary! We still could get some minor details we didn\u2019t know/didn\u2019t think about before even from the talks about fundamentals. They just weren\u2019t as helpful and mind blowing as we expected. However, for someone starting a Python journey, PyCon PL 2016 would be a perfect conference to learn about vast possibilities of Python application in science, machine learning, web, and education.  To conclude, I quite enjoyed PyCon PL 2016: I\u2019ve learned some new things and met some interesting people. It's also good to have a Python conference in Poland. I'm looking forward to PyCon PL 2017. Who knows, maybe I'll even apply my own topic?", "author": "andrzej-piasecki"}, {"slug": "mental-fatigue", "title": "Mental Fatigue: What Crashes My Day and How I Deal with It", "text": "The year 2016 is on its end, but the number of projects we take part of grows larger and larger. Thus, I\u2019ve decided to write on theoretically lightweight and universal topic but at the same time very important, especially for developers who basically work with their brains.  In this post, I focused on situations that can easily drain your mental power as well as come with some prevention approaches. Some may find it silly or minor, but I chosen situation that I personally find to be the most counterproductive as well as possible prevention methods.  Multitasking  Practically all of us take part in more than one project simultaneously. Moreover, all of us usually take part in multiple project\u2019s elements, so there is no way to hide as \u2018back-end developer\u2019 or \u2018front-end developer\u2019. Sound fun, right? I mean, you won\u2019t get bored.  However, such working conditions requires switching between contexts many times per day. And it can get very exhausting. According to numerous research on multitasking  switching between contexts can cost you even 40% of your productivity . And that is A LOT!  What can be done? Planning and sticking to the itinerary as much as it is possible. It may be impossible to dedicated one whole day to one project/task, but you can at least dedicate chunks of your day to each respective task. This way, you can focus on one thing at a time.  External sensory input  Too much of a sensory input for too long and you\u2019ll go nuts or at least you\u2019ll be extremely exhausted. I promise you that. From this perspective, an open-space office is a nightmare,  especially if you have very sociable co-workers that have a tendency to talk & joke a lot.  The most basic way of dealing with it is to go into headphones-on-coding-machine. Of course, after you burned 2 hours to discuss what headphones you should buy. From my experience, the best music to listen during work is not your favorite. Try movie or video game soundtrack - it\u2019s composed in such a way to not draw unwanted attention so it may be perfect for work.  You can also carefully reprimand co-workers who talk too much. Or go over the top and be very rude to everyone. No one will talk to you and you can even be encouraged to work remotely! Still, I don\u2019t think it\u2019s such a bargain...  Finding the most productive time of a day  Here\u2019s a tricky thing. For example, I find myself most productive between 6 a.m. to around 11 a.m. and in the late evening hours. Some of my colleagues come to work around noon and get into the working rhythm around 2 p.m.  Although working at hours that doesn\u2019t suit you is possible (most of us work like that anyway), you\u2019ll find yourself less exhausted working in the most productive time of a day. I guarantee that.  Don\u2019t know what time of day is your sweet spot? Just try for yourself. If your company generally doesn\u2019t permit picking your own working hours you may try to convince your boss, you\u2019ll be much more productive (thus profitable). Otherwise, tough luck.  Changing environment  Can\u2019t focus in the office despite working at the perfect time of a day in good conditions? Try a nearby cafe. Maybe work remotely from your home office. As I find it, the trick is not to bind yourself to one place but to change environment from time to time . This can help you fight legwork kind of situation, where days start to melt into single borderless timespan which can lead you to boredom and irritation, thus you become mentally exhausted.  If you have your own ways of preventing mental fatigue or situations that crash your productivity really hard, feel free to leave a comment!", "author": "janusz-gadek"}, {"slug": "offshore-software-house-developers-perspective", "title": "Offshore Software House from Developer's Perspective", "text": "There is approximately bazillion articles describing finding, building or managing offshore development team from startup founder or CEO/CTO perspective. Although there are some sources talking about how a good offshore software company should be like, there\u2019s not much about how it is to actually work as a developer in such team.  That, or my internet skills got rusty.  In this article, I\u2019ll talk a bit about what can boost productivity and make such project work for both founder/product owner and us, developers and what founder-developer relations are needed.  Building relations  As you could have guessed, building the right relationship between developers and product owner is one of the most important , if not the most important element. Without mutual understanding possibility of creating a successful product that will be both interesting challenge for developers and will cover the product owner\u2019s business goals drops very low. Near zero. I know, cliche. Yet, it really works that way.  Unfortunately, there is a number of product owners that, usually basing on bad past experience (i.e. devs that have poor actual tech skills and even worse business manners) don't even try to build a good relationship. They contact a dev team, tell them what they need to do, throw some money and a deadline. You can guess how this usually ends - everyone is in a shitty mood, the product is also incomplete or poorly written. Total waste of resources.  A founder or product owner has to remember that we, as developers, also want to build the best possible product. If we estimate that we need more time to complete the product, we usually know what we say. No one likes to ship a shitty product and perfection takes time.  Having good relations on product owner-development team line can not only save both parties much needed time and money but also enhance the product itself. Above all, a good software-house offers solutions to problems. You think you need an app? Tell us what\u2019s your business goals are, and we may find a better, more suitable solution .  Agile methodology  When you, as a founder or project owner have to choose the right software development team, ask them with what software development methodology they work in. If they\u2019re an agile software house, they may be your best bet.  In short, agile software development methodology has two useful elements: regular and active contact with product owner and so-called Minimum Viable Product (MVP) . This means that product owner can have total insight into development progress and can make changes midway. On the other hand, MVP approach guarantees quick, meaningful results. Product in its basic, usable form can give a massive amount of customer data that can be used to make it even better while cutting the cost of entire enterprise.  Downsides of outsourcing  Everything has its downsides. For me outsourcing has two major cons:  One of the rather irritating characteristics that many outsourced project share is that we cannot talk to about them. They can be one of the best products we ever made, where we used a number of very interesting methods, original architecture or brand new technologies. However, if they\u2019re under NDA, we cannot talk about them too much, so it\u2019s best to not talk about them at all. A shame. Could nicely widen our portfolio.  Another problem that may arise is the sheer distance and time zones differences (for example San Francisco-Berlin relations). Some details can be talked over through internet communication, yet it is very important to have a number of meetings face-to-face . Mikita Mikado nicely underlines the importance of personal contact in his article for TechCrunch . It may be difficult, but from our experience, we know it pays off.  Final thoughts  Even though working as a part of offshore software development team can be sometimes hard or frustrating, it is definitely an interesting and inspiring experience . By going global, you can partner with some pretty amazing people, got very demanding and challenging problems to solve, learn new things and, of course, create some innovative software.  If you think we will be an asset to your vision, feel free to contact us right away !", "author": "krzysztof-krzysztofik"}, {"slug": "teonite-full-stack-developer-pl", "title": "TEONITE Rekrutuje - Full-Stack Developer [PL]", "text": "Pilnie poszukujemy prawdziwego (samozwa\u0144czego czy te\u017c nie) specjalisty. Twoje do\u015bwiadczenie jest wa\u017cne, ale jego brak nadrobi\u0107 mo\u017cna ch\u0119ciami, samozaparciem i otwartym umys\u0142em.  Let's talk!", "author": "janusz-gadek"}, {"slug": "spring-cleaning-retrospection-of-the-last-year", "title": "Spring Cleaning - Retrospection of the Last Year", "text": "Spring has come so it's finally time for some spring cleaning! While most yearly retros are done around New Year, we like to do it on the first days of spring, with clear heads and without any rush.  But first, we did some ACTUAL spring cleaning to boost our working space a bit. Nice, huh? I particularly like the new plants picked for their air cleaning properties and looks. In that order.   Retrospection of the last year  For one, we\u2019ve welcomed new partners! As for today, TEONITE is managed by five people in total. All of them have huge experience in general IT development but also data science, machine learning, and project management.  Our team has also grown a little bit. Bringing new person into a team is always a challenge: Is he good? Can we depend on him? Will he fit in? Can we learn something from him and can he learn something from us? Luckily, all of the guys that joined TEONITE proven to be trustworthy, hardworking and clear-thinking. Yet, we\u2019re still in the middle of the hiring process, looking for senior full-stack developers.  We also did some great projects. We have made a quite beefy CRM for Sport Club Sp. z o.o. which is one of the biggest online sports stores in Poland. It was a lot of fun working with their network and phone system. Also, Sport Club Sp. z o.o. CRM was one of the fastest projects of this kind we ever did - the entire system was built, tested and deployed in just one month. SportClub team presented great communication skills which made everything go very smoothly.  We have taken up some serious data science projects which are still ongoing. We also worked together with Polityka Insight on their new mobile platform which once again proved our skill in building multi-platform web and mobile publishing systems. We also did some nice data visualization for Splentum which specializes in financial data aggregation and analysis. You can get a taste of it at Evolution Chamber.  As for Evolution Chamber - we\u2019re hardcore supporters of open source community. Because we use libraries and resources made by someone else on a daily basis, we decided to give back what we borrowed from the community. Thus, we released Evolution Chamber which is a place for all of our open source projects, modules and libraries . There you can find, among other projects, our Satellite Chart Library, SuperResoultion (convolutional neural network for image scaling) made by our senior developer and TEONITE\u2019s partner Andrzej, as well as Angular2-Auth - Angular2 module for backend Token Authentication.  2017 started with a bang. Fiszki Polityki is a mobile app from Polityka on which we and many other experts in their respective fields worked for a whole year.   The approach to the daily press and quality content is very interesting and we\u2019re proud to be part of Fiszki team. You can read our thoughts on Fiszki at our blog .  So, what\u2019s the plan for the rest of 2017?  We surely want to release and back up the open source community much more. Among other, smaller modules, we have at least one major project in our pipeline to be released in April/May so keep in touch and check out Evolution Chamber. All I can say for now, is that its main goal is to boost teamwork and motivation for testing and rewriting code.  We have a constant stream of projects and contracts and there\u2019s much to be done. Still, the more the better! We would especially like to participate in more projects concerning huge datasets and do some data science projects, so if you happen to have something in mind, feel free to contact us.  As mentioned before, we\u2019re also looking for new developers . We\u2019d like to grow a little bit more as a team, both in numbers and in quality, but new teammates need to be the best specialists in their field of interest. Quality over quantity. Are you up for the challenge? Let\u2019s talk! We\u2019re currently hunting for senior full-stack developer .  Full of hope, we're determined to produce well-written quality code, to create technology that helps and not annoys and time to still have some fun in our busy lives. Which we also wish you all!", "author": "janusz-gadek"}, {"slug": "fiszki-mobile-app-polityka-teonite-development", "title": "Fiszki: a new mobile app from Polityka powered by TEONITE", "text": "We\u2019re very happy and excited to be part of another huge project by Polityka , a new mobile app created by a team of specialists from different fields of expertise - editor and journalist Mariusz Herma, all editors engaged in the development and testing, Maciej B\u0142a\u017aniak from \u0141adne Halo as well as Gabriela Kunert and her marketing team.  It was a great experience to work with all of them on the Fiszki development.  Fiszki is a mobile application focused on delivery of quality information. In this article we\u2019d like to share our thoughts on Fiszki app; what we find as the most important design choices and how it approaches issues Polityka\u2019s team defined.   It was quite a challenge for each of us in the project. As a 60-year-old magazine, we wanted to connect with 20-year-olds. And offer them our in-depth articles in a rearranged and concise form, but without losing any merit. Our graphic designer was asked to come up with something modern and old school at the same time, and to recreate that paper-like feeling on a smartphone screen. And the TEONITE team had to implement all those quirks and provide a seamless and fun experience.  Mariusz Herma, Fiszki Polityki   What is Fiszki all about?  In short, Fiszki is a mobile publication platform, that gives its users a wide range of daily information on topics such as economics, politics, culture, business and sports. even though it sound like any other info app available on the market, there are some things that clearly differentiate Fiszki from other similar mobile applications.  First thing is, Fiszki is not a simple aggregation of content from different popular platforms. All of the articles are written by handpicked team of experienced journalists and editors who thoroughly check and verify all of the information before publishing anything.  Secondly, you won\u2019t get overwhelming walls of text, overly fat reports and encyclopedia-like articles. Instead, all information are presented in very condensed form (on which I\u2019ll talk a bit later) where each sentence of any publication must be meaningful and add new facts to whole article. There\u2019s no place for empty journalism and useless claptrap.  Here\u2019s a short video presentation of the app from Fiszki Polityki:   \"Fiszki Polityki - try new app from Polityka newsmagazine\"  Fiszki - for people by people  Now, a fun fact that is obvious from Polish language perspective, but need some explanation for English audience: Word \u2018fiszki\u2019 can be directly translated in English as \u201cflip cards\u201d. Moreover, its pronunciation is very similar to English word \u2018fish\u2019 (\u2018Fiszki\u2019 are exactly pronounced as /'f\u026a\u0283ki:/). Thus, the flipcard-fish logo. All in all, it makes it a really good pun in Polish.  Main target of the Fiszki mobile app are young people. A big, thoroughly executed research of a target audience was the cornerstone of Fiszki app. In short, Polityka and Mariusz Herma made a long-range research with a group of volunteers between 15 to 20 years old. The main goal was to find how young people deal with information noise, what they really want to know about the words and in what form should the information be presented to them. The research ended with a hackathon during which all participant was asked to design the form in which they would like to get their daily set of information.  And that\u2019s what we like: working with strictly determined requirements based on exact data.  Design with UX in mind  Merits for Fiszki\u2019s design should go primarily to Maciej B\u0142a\u017aniak from \u0141adne Halo creative studio. Each article is presented as a set of digital flip cards. This form of presentation forces authors of articles to be precise, facts-oriented and as meaningful as possible. From the user experience perspective, it drastically cuts the information noise.  Of course, the app has to be interesting. This was accomplished by colorful design and appropriate approach to the UX/UI. We all took a great care to ensure that each action a user can take in Fiszki is extremely satisfying. Every interaction with the application is smooth. The interface is very intuitive. Fiszki mobile app has a proper user onboarding elements included, yet we\u2019re almost sure it could easily go without them. Still, better safe than sorry.  TEONITE\u2019s role in Fiszki development  Our job as TEONITE was to forge all of the mentioned ideas into stable, usable product. Of course, we had to write the mobile applications for iOS and Android while achieving smooth UX and UI feeling.  However what was evenly important was to make sure that all back-end related services are working correctly. We had to build the system that could easily support thousands of simultaneous user while still being fast and bug-free (e.g.subscriptions have to work correctly, user doesn't have to wait for chosen article). We also had to build CMS for editors and journalists for adding and managing content. carried out from the technological perspective and that the app itself is well developed and thoroughly tested.  All in all, there was a ton of requirements and issues to attend to - some were big, some were small, all were evenly important. Everything was thoroughly tested - we made sure that the app runs fast, all notifications work as intended, everything is safe and secure and no unwanted interactions will annoy Fiszki\u2019s users.  Up and running  Fiszki is now available for both Android and iOS platforms at App Store and Google Play respectively. Stay tuned for more information on mobile apps development and programming challenges.", "author": "janusz-gadek"}, {"slug": "castlabs-new-backed-for-dece-ultraviolet", "title": "Joint project with castLabs - a new backend for DECE's UltraViolet ecosystem", "text": "We\u2019re very happy to announce that our cooperation with castLabs in the development of backend systems for the UltraViolet ecosystem, has completed and can be considered successful. Below we outline the project\u2019s objectives and the project\u2019s importance for the usability of UltraViolet.  What is UltraViolet?  In short, UltraViolet is a cloud-based digital rights storage system, enabling consumers to access their purchased content across all devices using many differnet services. UltraViolet was first announced in 2010 by DECE (Digital Entertainment Content Ecosystem), a huge consortium composed of major film studios, e.g. Universal Studios, Sony Entertainment Pictures, Warner Bros. Entertainment, Internet-based companies and ISPs, retailers, cable TV companies, network hosting vendors and many more.  UltraViolet from user perspective  Every time you get a copy of a DVD or Blue-ray Disc distributed/produced by one of the DECE partners and labeled with the UltraViolet mark you can easily add your new title to your UltraViolet Library by redeeming a code that comes with each copy. This gives you an unlimited access to your movies throughout different devices and platforms. Pretty neat. You can also directly buy digital versions of movies and TV shows from UltraViolet patricipating services.  What was the project all about  We took an active role working with castLabs development team in building a totally new version of DECE\u2019s UltraViolet Coordinator service \u2013 the cloud-based servers, databases, and web services API - ensuring fast and error-free communication between UltraViolet ecosystem and various retailers and content publishers.  Results  The service ran smoothly during December holiday peak and no major issues were reported which, considering the sheer numbers involved, makes it a great success. UltraViolet has over 28 million users with over 250 million movies and TV shows in 13 countries. During holidays (24th/25th) the number of API calls peaked at 1M per hour, and on New Year\u2019s Eve it rose up to 1,7M transactions per hour. And everything worked just fine. If that\u2019s not a success, I don\u2019t know what is.  Aftermath  The project has ended successfully. We like to treat the sheer scale of this undertaking as a good proof of our capabilities and high skill level, but we\u2019ll happily accept even more challenging project anytime.  A good thing that comes from such joint projects is the possibility to work in a new environment and with new developers which is very motivating, especially when you see they know what they\u2019re doing. All in all, we certainly hope for further cooperation with castLabs.   TEONITE really did their part. They exhibited high skill in all-round programming, while sticking to the development requirements and deadlines. With their contribution of expertise and cooperative spirit we made swift and solid progress.  Piotr Buli\u0144ski, castLabs Development Lead   About castLabs  castLabs pioneers software and cloud services for digital video markets worldwide. The company provides solutions to easily enable the secure distribution of premium movie, TV, and audio assets for high-quality video experiences. Their range of applications and services are designed to help businesses deliver DRM-protected content over a large selection of consumer devices and platforms. castLabs is based in Los Angeles, California, and Berlin, Germany. To learn more about castLabs products and services, please visit castlabs.com .", "author": "kamil-chudy"}, {"slug": "web-applications-development-working-on-the-workflow", "title": "Web Applications Development Prelude: Working on the Workflow", "text": "First of all, we\u2019re finishing a major refactoring project - the second version of a huge KPI management system we did originally around two years ago. In a little more than half a year, we did some serious changes to the code and, most importantly, we decided to transfer it from AngularJS to ReactJS, mostly because it worked brilliantly with internal projects and we wanted to see how it fares in production.  The important bit here is that none of us had any previous contact with huge React projects, only some side-tasks, and internals. Through this refactoring project we gained two things in general: a new, enhanced, specialized tech stack for web applications, and a better understanding of scrum Agile framework.  Today, as a prelude to the meaty, code-filled stuff, I\u2019d like to talk a bit about all good and bad decisions regarding our workflow, team management, and scrum cycle.  Let\u2019s start with decent workflow  We\u2019re a team that embraces the agile methodology, so one of our favorite tools/frameworks offered by agile approach is scrum. In its core, scrum is rather easy to understand yet it\u2019s not always as easy to implement as it seems. Saying \u201cWe\u2019ll be using scrum \u2018cos it\u2019s productive and efficient\u201d isn\u2019t enough. Each team member has to understand exactly why it is efficient and has a positive impact on the productivity for it to be really productive.  At first, we collectively assumed that we all know what scrum is about, what parts it consists of and why. And it created some problems with the workflow. Most likely, the source of this issue could be having new people in the team, who had different understanding of scrum. We also assumed that all aspects of scum must be present because it worked just fine in past projects.  We also didn\u2019t take specificity of this project into account at first.  Project\u2019s start was quite painful from team management point of view. We started with a model scrum. We had all the plannings and groomings you need for a good scrum cycle. At least in theory. We had formed our sweet Definition of Done. We had a retrospective after each sprint. Also, our CTO, Micha\u0142 Gryczka, played the role of a product proxy.  I believe it was possible to finish the project that way. However, it would be very painful and would most likely yield worse results. I also like to believe that there\u2019s always place for improvements.   Transformation of the scrum cycle  The first thing we did was to establish regular contact with the product owner. Don\u2019t get me wrong - Micha\u0142 is a very good project manager and business software specialist. He surely knows and understands his job. However, because of project complexity (predictive analysis formulas, portfolio analysis, financial forecast, various simulations etc.), we had to have direct contact with the product owner who is strictly a financial expert. He exactly knew what functionalities are the most important. Also, working in corporate finance himself, he deeply understood user stories and use cases. Thank\u2019s to this shift, we began to better understand why certain features have to be displayed in certain ways, what data the product users want to have visualized, etc.  Ok, so we got rid of the product proxy position to get closer to the product owner. Next on the list was a natural enemy of any team - endless meetings.  This one was rather simple to fix. We began to do grooming with product owner ourselves (earlier it was done by product proxy) which made separate planning unnecessary - we knew our velocity, we knew all the requirements so it took 5 minutes to plan the next sprint. When everyone understands what each feature does and how it relates to other features it clear what feature has the priority. All in all, instead of two ~4 hour long meetings that leave you tired, unmotivated and slightly confused, we did three rather short and intensive grooming meeting directly with the product owner. Of course, if there were no topics to discuss, such meeting was canceled.  Don\u2019t underestimate daily stand-ups!  Now a little side note that has some connection to the topic. I have some associates don\u2019t see the value of daily stand-up meetings. I beg to disagree. It\u2019s really worth your time. Like, REALLY worth your time.  Have a difficult issue to resolve and can\u2019t find an appropriate solution? Signal it during stand-up. You can be almost certain, someone will suggest a solution. Probably something you haven\u2019t thought about.  Nothing sets up daily priorities as good as daily stand-ups. And, above all else, daily stand-up meetings let you know what your teammates do and what they plan to do next, so you can plan your own work accordingly. This is especially important in case of hard, time-consuming projects when there\u2019s no time to talk with your teammates in \u2018free time\u2019. Thus, stand-ups helped us keep on the track of the project as a whole.  In the context of this project it did just that: helped us keep each other informed and find solutions to problems in-hand. I really encourage all opposed devs to try it.  The payoff  Picking and adjusting an appropriate team management methodology according to the project nature (it was basically an R&D project for us) and requirements is a very important aspect. It can either lead your team in the endless pit of miscommunication and unfulfilled deadlines or help them get the most \u2018pro\u2019 out of \u2018productive\u2019.  In the next part of Web Applications Development series I\u2019ll talk more on the subject of our approach towards React in web apps development. If you have any interesting story regarding team management problems and solutions be sure to share and comment.", "author": "lukasz-pilatowski"}, {"slug": "docker-registry-2-frontend-haproxy-ssl", "title": "Docker Registry 2 frontend with HAProxy and SSL", "text": "All our services run on Docker and are load balanced using HAProxy . One of those services is Docker Registry 2 .  If you have the same case, the configuration for proxy/LB Docker Registry 2 using HAproxy via SSL is not that sreightforward. So here is a working and ready configuration for that:  frontend registry  \n        # we need to bind both to http and https\n        # because registry communication will fail\n        bind FrontendIP:80\n        bind FrontendIP:443 ssl crt /etc/ssl/registry.pem\n        option forwardfor\n        http-request set-header X-Forwarded-Proto https if { ssl_fc }\n        redirect scheme https if !{ ssl_fc }\n        acl host_registry hdr(host) -i yourRegistry.domain.com\n        use_backend registry-cluster if host_registry\n\nbackend registry-cluster  \n    redirect scheme https if !{ ssl_fc }\n    balance roundrobin\n    server node1 registryNode1IP:5000 check\n    server node2 registryNode2IP:5000 check", "author": "robert-olejnik"}, {"slug": "fixing-python-soap-by-using-postgresql-xml-and-jsonb", "title": "Fixing Python SOAP handling, by using XML and JSONB fields in PostgreSQL", "text": "Synchronization of huge amount of data between two systems can sometimes be problematic, especially if one of the systems is accessed through a slow API.  The service we had to integrate with was exposed through SOAP API. The API itself was slow and it had ~4,5 seconds time-lag per 10 records, but there was a bigger problem - Python SOAP libraries/implementations are really, really slow, f.e. +20 sec per request to process them.  So in a case of 500,000 records, it would take approximately one week to get all of the data. So, we had to find a way to boost the synchronization time.  Here are all the details about what we had done to find a suitable solution for this problem.  Attempt 1: Finding a suitable Python library  The first idea as mentioned earlier - was to find a suitable Python library. We found the suds library that allows SOAP to Python objects transformation. Unfortunately, suds library\u2019s last update was from five years ago. After a thorough search, we found a suds-jurko , a fork of the original suds. In theory, module did a query to the server and got the objects. Then we would have to map the received objects to our database. However, the matter of slow synchronization lasted. In practice, the module needed 20 seconds to parse a single API response . Add 4,5 seconds from servers application and you get almost 25 seconds per 10 records. We wanted to faster synchronization, so we abandoned the idea of using suds library.  Attempt 2: Implementing a Java wrapper  The second approach was in some way similar to the first \u2013 we could utilise some Java tools and generate whole POJO client. In fact InteliJ IDEA was very helpful with that - it tool 20 minutes to generate simple POC. But it would add another layer of abstraction and technology to the system. So finally we abandoned this approach.  Attempt 3: Dump all XML responses and work with them locally  Finally, we decided to store all API responses (raw XMLs) the way SOAP api delivered them and then think later about import method.  The data dump took roughly 35 hours; for some reason,some of the data had two endpoints on the SOAP server. Finally, we had all raw XML files in our database (PostgreSQL with XML native types).  All we had to do is to come up with some kind of mapping and an importer.  The solution   We used Python xmltodict library to transform XML fields into a Python dictionary .  Then, the newly formed Python dictionary would be stored JSONB field in Postgres.   Seems we hit a bullseye. It turns out PostgreSQL is quite good at filtering over nested JSONB fields:  Before index:  syncDB> select count(*) from core_jbjorder where data -> 'client' -> 'delivery_address' ->> 'city' = 'Szczecin';  \n+--------+\n| count  |\n|--------|\n| 198762 |\n+--------+\nSELECT 1  \nTime: 3.279s  After index:  syncDB> create index on jbjorder ((data -> 'client' -> 'delivery_address' ->> 'city'));  \nCREATE INDEX  \nTime: 3.910s  \nsyncDB> select count(*) from core_jbjorder where data -> 'client' -> 'delivery_address' ->> 'city' = 'Szczecin';  \n+--------+\n| count  |\n|--------|\n| 198762 |\n+--------+\nSELECT 1  \nTime: 0.018s  The use of JSONB allowed us to gradually transfer our data from document-like JSONB field into old, good relational schema.  Lesson learned  Splitting responsibility for data fetching and transformation was a good decision. First was to store all of the raw XMLs to save time before we even came up with import implementation - it is always easier to work with data locally. The second was the application of the JSONB field in PostgreSQL.  So general cue in tackling such problems would be to divide it into smaller problems and attacking them one by one. These way you can focus on simple solutions and engage more team members in creative process of problem solving!", "author": "jacek-chmielewski"}, {"slug": "convolutional-neural-networks-as-an-answer-to-image-scaling-issues", "title": "Convolutional neural networks as an answer to image scaling issues", "text": "Let\u2019s face the truth.  You all thought about us as Python and Django lovers and Angular freaks. Even if you are right, there\u2019s more that meets the eye. I, for one, made my own, now not-so-private research on the topic of convolutional neural networks.  What I wanted to do, was to test the image scaling capabilities of the convolutional neural networks, especially the issue of scaling up low-resolution images . Although the typical algorithms such as Bicubic or Lanczos make it pretty well, they usually fail on big scale-ups around 500%. You can simply see the pixels with a naked eye. So, I wanted to see if the convolutional neural networks can do it in more intelligent and efficient way.  Those of you that are interested can check out the full repository of this neural network at our GitHub .  Technologies and Architecture  In my neural network research, I decided to use Keras which is a modular neural network library written in Python. The strong points of Keras are modularity and minimalism to make each module short, simple and understandable at the first glance. Additionally, it\u2019s really easy to create new modules (classes and functions) so it\u2019s a preferred tool for advanced research. Keras is designed to work on top of Theano , also a Python library helpful in defining, optimizing and evaluating mathematical expressions. Using Theano on CUDA Nvidia framework and using GPU to distinctly accelerate the evaluation process was also very helpful.  For my research, I used a convolutional neural network of a simple structure. The convolution layer has 150 9 x 9 filters with a 200 x 200 sized images being the input. After that comes the activation layer (RELU) followed by output layer. The optimizer used in the network is Adam on default parameters.  Network Training  The network was trained on a couple thousand images from the Image-net.org . For the training of increasing twofold, the input image was twofold reduced and then twofold increased. The output image was the original image.  To back up for a 2GB limited memory of the graphics card, images of a bigger resolution were divided into 200 x 200 pieces. There were close to 5,000 images during a one learning epoch. When the training process stopped showing development on the given training data set, a new data set was automatically downloaded.  To deal with the jpg artifacts which, if not erased before the image size is increased, can and will drastically influence the image quality, I decided to make a second convolutional neural network of a similar architecture which was trained by models of images with very low jpg compression and their original counterparts.  As you can see below, the effects are at least acceptable.  Original image:  Image scaled-up with GIMP and Lanczos filter:  Image scaled-up with Lanczos filter and corrected with the neural network:   Standard neural network use case  If we take a closer look at the application of neural networks, it becomes clear that there are certain fields on which neural networks do a very good job. For one, financial and economic forecasting is heavily influenced by machine learning. Prediction of the stock market price change is one of the best examples. For such a fast, day-to-day business, it is extremely important to have a fast and accurate tool for price forecast for both macro and microeconomics. Similar, yet a bit different application of these algorithms, can be found in case of sales forecasting and customer research, thus can influence overall customer service and give the given business accurate data about customer-product relations.  Thanks to modern hardware specifications the machine learning and neural networks, although still in development,  became very effective and will become even more useful in near future. For these reasons, it is most natural for TEONITE to use such algorithms for fast and accurate economics data predictions and to analyze huge databases efficiently.", "author": "andrzej-piasecki"}, {"slug": "successful-user-onboarding-guide", "title": "Basic elements of a successful user onboarding", "text": "People say that good first impression is of utmost importance. An application may be treated similarly, if not the same way. Make a bad first impression and your newly-released app is dead right away.  When we talk about apps, the \u2018first impression\u2019 is referred to as user onboarding and it covers all design elements corresponding to the conversion of a new user to a regular customer of your product. You don't want your app to die on launch day, right?  What the user onboarding is exactly?  As mentioned before, it is a number of design traits and solutions that can help you change almost any fresh user into a regular. User onboarding consists of things such as sign-up form, tutorial policy and regular, clear feedback from the application and it covers both macroelements (whole screens and modules) and microelements (design of the \u2018next\u2019 button). To be plain and simple \u2013 user onboarding is the first couple minutes a user will spend on your application. Making it worthwhile for the user will make it worthwhile for you.  I\u2019ll be talking about three main areas in which you can boost the user onboarding ideas - landing page, sign up and tutorial design . Paying attention to these three elements can easily raise the successfulness of your user onboarding.  Landing page \u2013 the first impression of 'the first impression'  Let\u2019s start at the beginning.  A landing page is the first contact of a new user with you and your product.   A standard procedure is to throw in some inspiring, stylish banner with a nice slogan speaking directly to your user.  Show your user what she/he can do with your app rather than what the app can do. Try not to advertise your product on your landing page. Instead, give a social proof. You can throw some good quotes and third parties\u2019 opinions about your products.   Kickstarter does a great job with their landing page. You are constantly reminded why you came here in the first place. Also, you take a look at our homepage to see what I mean exactly. Of course, you can get creative with your landing page. Check out these 15 best landing pages .    Sign up   I can safely say that almost all apps and platforms require sign ups to use them. And this is the first element that can go tragically wrong. No one likes to be asked too many questions and be spied on before they even know that they want to use your app for sure. And the feeling of being inspected doesn\u2019t help.  It may be a good idea to require e-mail and password at the start. If the user wants to fill in all the details about his company, location, his dog\u2019s name and favorite food she will fill it in later. It is almost mandatory to offer sign-ups with social media accounts such as Facebook, Twitter or Google+ accounts. This doesn\u2019t force a user to make a new, separate account for your app. It makes the sign-up process as short and easy as it is possible while offering you (the app owner) good insight into user's profile. I\u2019d say it is a win-win situation.  You may take Gmail as an example of too complicated and intrusive sign up form. The fact that people sign up for Gmail anyway is not a valid argument. Though, it can explain why it still so complicated.   On the other hand,  Dropbox offers some really good sing up form . Everything is clear. Dropbox offers a sign up with Google account and does not require too much information.     Tutorial   Now, this is an extremely important element for a successful user onboarding. To make an easy to follow, clear and not intrusive tutorial for your app is truly a challenge. You may want to consider the things mentioned below:  \u2022    Make tutorial in such a way that it will remind your user why he really wants to use your app. Don\u2019t write about what the app can do, but rather what the user can do with the app. A small but a big difference.  \u2022    Incorporate progress marker to your tutorial. I personally think that it is nice to know which step I am at and how much knowledge I still have to absorb before I can use the app.  \u2022    Even if your app is rather complicated in use (which I will not comment on here), make it possible for the first time user to skip the tutorial. There are some of those are allergic to the tutorials.  \u2022    Thank your user for doing things and cheer on his success. A simple, yet rewarding element for both user and you. Psychologically speaking, when you reward your user with messages like \u2018Good job!\u2019 and \u2018Perfect\u2019 you give them a positive response corresponding with the correct use of your app. This gives off a good vibe and makes your user remember things faster.  \u2022    Refrain from communicating (by messages, design of the tutorial etc.) with you user like he\u2019s 10 years old. You know that people aren\u2019t dummies, right? Especially the people using your app shouldn\u2019t feel like that.  Below you can see an example of a well-designed tutorial. Google tells you at which point of the tutorial you are when you personalize your Google+ account (the right side of the screen).   They tell you what can you do with the app (not what app can do)!   They also inform you why you may want to do as they advise you and what will be the outcome of your action.   They refer directly to the user changing a simple tutorial into a more private relationship with the user.   Paying attention to the details  Pay attention to the details. Make sure that the buttons responsible for the actions you, the app owner, desire from the user are somehow highlighted. Nothing too forceful, though. Just make it clear what your user has to do to make his contact with your app successful.  Make sure you personally talk to your user through informational windows and advice bubbles. If you cannot decide between \u2018Create an Account\u2019 and \u2018Account Creation\u2019 on the head title of sign up page, go with the former. You basically communicate thing to each user separately, not all of them at once - each user will fill more special.  Finally, remember that these are just some general remarks \u2013 even if not very original they may help you identify some issues much sooner and prevent a disaster.  Comments and afterthoughts  User onboarding is a very important issue of any newly launched app or product. If you manage to create a great first impression you will feel it, trust me. The conversion rate of new users to regular users will surely go up. Additionally, the people responsible for marketing campaigns won\u2019t have to work too hard to fill in for the user onboarding mistakes.  For further reference, you may want to check out the teardowns made by Samuel Hulick , a designer and an expert on the topic of user onboarding from UserOnboard.com .", "author": "janusz-gadek"}, {"slug": "short-guide-to-website-readability", "title": "Short guide to website readability", "text": "Have you ever came across a website that offers very good content and has good design, yet you feel uncomfortable while reading their articles? I know I have. Thus, I tried to find the main reason and think about possible countermeasures for such phenomena.  I won\u2019t be tackling the topic of website design head-on. Instead, as I tend to work with written text, I will focus on website readability and include elements of web design when relevant. For those who may not know, the whole notion of readability is connected to written content. Higher readability also means better chances for the first-time reader becoming a regular one.  What you want to say and how you want to say it  If you are publishing a website, it simply means that you have something to convey. Doesn\u2019t matter if you want to boost your company sales, share your cooking ideas or just have your own website full of funny cats (which makes the majority of the Internet). All of this content needs to be presented in simple and comprehensible, yet not boring way . That rule applies to both forms of the presented content and content itself.  Font types  The type of the font you use is important. And I mean like really important. Generally, the main text shouldn\u2019t be written using fancy fonts. Don\u2019t make the readers\u2019 lives harder. Also, keep in mind that most of your potential readers will just skim through the text. If you really want to use one of your favorite fancy fonts, the titles sections are the place to do it. This way, you will have both easy-to-read and not too simplistic content.  Font size and line spacing  It isn't necessary, but it still may be a good idea to define font sizes in percentage that relates to the text size in body section (always defined in points, pixels, or em). This will make your website more responsive \u2013 remember that people use different devices and different web browsers with different settings. Luckily, many devices scale the text themselves which partially resolves the responsivity issue for you. Also, remember to make a clear difference in font sizes between main text and titles, because just using font types isn\u2019t enough.  When it comes to line spacing (vertical distance between lines of text) it all depends on your design and text objective. For the body text, it may be wise to not go any lower than 120% of the point size and not any bigger than 160%. Still, the most important thing is to set the line spacing the way that will make reading easier and will look good.   Optimal line length  There are two main approaches to the optimal line length issue:   Many professionals consider 50-60 characters per line as an optimal line length . When you make your lines too wide, it\u2019s hard to keep focused on the text, especially for readers like me who like their browser fonts small. On the other hand, making the lines narrow leads to very frustrating and tiring experience of \u2018Go back to the beginning right now\u2019 and it can easily mess up reader\u2019s rhythm.  However, if you poke around the internet some more, you will surely find those that stay closer to the 100 characters per line . And, to be honest, it is still highly readable.   All in all, it depends on the overall design , the topography of your website and your personal preferences.  Keeping reader's attention  As an author who wants to be read, you need to keep your reader focused on the topic. Here are some suggestions on how to do it:  \u2022    To hold the reader\u2019s attention you may want to use images, however, it is not necessary. Of course, the images you pick need to be content relevant , but not exactly content heavy. Just make me want to read the next paragraph. If you happen to use images and graphics, make sure you implement them clearly (leave some space between text and graphics) and that they will not slow the loading time of your website too much.  \u2022    Highlights are also a good way to make content clear and understandable. Just remember to highlight important words and phrases , not some random elements.  \u2022    Use listings. Especially, if your reader likes to scan the text first. It also makes your content more organized  which is a perfect thing for step-by-step articles such as cooking recipes.  Contrast and background images  We all like our website pretty. Throw in some nice background in there. But be aware of the implication of messing too much with the background. Don't make it too chaotic or your text may be simply unreadable. Just keep a high contrast between text and the background . Some people like to read white text on the dark background; some prefer traditional, dark-colored fonts on white or very light backgrounds. Either way, keep the high contrast.  You can make your work easier by checking the contrast with one of many free tools available online.  Additionaly, you can check if the colors you pick can pass the WCAG 2.0 tests (website accessibility for people with sight disorders). If the colors you picked passed the tests, you can be sure that the contrast will be high enough.   The tip of the iceberg  I hope some of you will find these tips even a little bit helpful. However, if you thought you now know everything about readability I need to disappoint you \u2013 the ideas presented here are just the tip of the iceberg and was picked according to what is important in my personal  opinion.  Lastly, even the highest possible readability level won't do much good if the content itself is boring.", "author": "janusz-gadek"}, {"slug": "angular2-auth", "title": "Angular2-Auth for Django REST Framework", "text": "Three months ago we've released Angular-DRF-Auth , an Angularjs library for user authentication based on Token Authentication in Django REST. Now, we have made a similar module for Angular 2 Framework. You can get the angular2-auth at GitHub .  Angualar2-Auth helps in user authentication for an API built in Django by providing access control for protected components, allowing to easily obtain a token and store it in localstorage for further usage.  Features:   Time efficient: cut on boilerplate code  Simple log-in form & redirection to log-in form if unlogged user tries to access the application  Obtaining a token only by configuring the obtain-token url  Storing the token in localstorage so it can be added to every request passed to the backend  Simple design based on component paradigm  Angular 2 Route support by adding a custom protected router outlet   Open Source  This Angular 2 library is published open source. We also plan to develop it for other backends as well as other types of authentication. Full angular2-auth documentation (installation process and basic usage) can be found at here, at TEONITE GitHub .", "author": "kamil-chudy"}, {"slug": "angular-websites-and-web-apps", "title": "7 well-known websites and web apps built in AngularJS", "text": "AngularJS is by far our favorite framework for frontend web development. It is a complete solution for dynamic, single-page web applications that has all of the necessary tools integrated.  Led by curiosity, I wanted to find out what big names use Angular for their websites and web apps (we already talked about famous Python coded web solutions some time ago). Taking into consideration a high popularity of AngularJS, the list could easily reach hundreds or even thousands of domains. Thus, we decided to narrow it to 7 cases in which frontend was powered by AngularJS, plus 2 bonus websites made by us .  1. Udemy  Udemy is currently one of the biggest online learning platforms in the world. This US based online training marketplace offers more than 40,000 courses and has around 11,000,000 students. An online learning platform of that size has to work fast. Udemy has decided on the dependable AngularJS framework for their frontend needs.   2. GrubHub  GrubHub is an online food ordering platform that serves as a middleman between you and the restaurant in your vicinity. Among jQuery and YUI, GrubHub's frontend is also built with AngularJS.   3. Google Trends  We couldn\u2019t possibly omit one of the Google services, could we? Google Trends is a dynamic web app that gives you the opportunity to filter and check specific phrases\u2019 search volume in comparison to total search volume across a world\u2019s region or country. It may easily serve as a supplementary tool for online marketing.   4. Echoes Player  Echoes Player is an alternative to the browser version of YouTube built in Angular. Intuitive and appealing overall design and boosted UX are just some of the many strong points of Echoes Youtube Player.   5. VEVO  A huge, multinational platform hosting music videos from the most popular artists. It is a joint project of the biggest music corporations such as Universal Music Group and Sony Music Entertainment. Having 13,000,000+ visits per month, Vevo app has to be efficient and fast.   6. Ancestry.com  Ancestry.com is a website helpful in understanding genealogy, family tree, and family origins. In addition to the thorough check of your family tree, they offer a web application specifically designed for easy management of the family hints they present you with.   7. Amazon  Amazon is one of the leading companies in adapting and developing new solutions and technologies, such as Amazon Dash Button for recurring orders or AmazonFresh for fast online grocery shopping. It shouldn\u2019t be a surprise that Amazon was one of the first big companies that adopted Angular as a solution for one of their pages - Content and Devices manage page.   Bonus Round  We decided to include these two platforms because of two reasons. First, these websites were proudly developed by TEONITE with the use of Angular and we really like to share our projects. Secondly, these platforms are also quite popular in their respective fields of interest.  Of course, they are not as popular as Amazon or VEVO, but they still shouldn't be omitted.  TechSoup Polska  The Polish branch of a big platform for NGOs, TechSoup Poland, is a great example of what can be done within Angular. We already talked about this project and you can read the TechSoup.pl case study at our blog.   Ochotnicy Warszawcy  Ochotnicy Warszawcy was a project we did together with the Capital City of Warsaw. It is a platform that connects different organization (usually NGOs) with potential volunteers. Through Ochotnicy Warszawscy, an organization can publish all information about an initiative, as well as what skills does potential volunteer need to have to be helpful. On the other hand, a volunteer can easily find all initiatives that interest her or him and can check if has all necessary skills to be truly helpful.   If you have any interesting or well-made websites and web apps that were made in Angular, feel free to share your thoughts.", "author": "janusz-gadek"}, {"slug": "code-refactoring", "title": "Thoughts on Code Refactoring, Agile Development and Technical Debt", "text": "If you\u2019ve never heard about code refactoring or you're not very convinced of its value, now is the time to patch things up. Code refactoring practices often happen to be omitted which can become very problematic at advanced stages of product development or in the case of a product in constant development.  What does code refactoring exactly mean?  Code refactoring is a process of restructuring and rewriting parts of code in order to improve nonfunctional elements and attributes of software without changing its functionality. In short, we rewrite code to make it more readable, simple and optimized.  Some of the symptoms that suggest need for code refactoring are parameter lists and methods that are too long (also called bloaters), duplicated and/or dispensable code or even variable names that aren\u2019t intuitive. All these symptoms and more are generally referred to as \u201ccode smell\u201d. Now, why do we write \u201cincorrect\u201d or messy code in the first place?  Agile Development and Technical Debt  From agile development perspective, we begin our work with just a basic concept, a minimum viable product. In time, we design and implement new functionalities which change project as a whole. We define new features that were not taken into consideration in the first design. It is a natural part of agile development. All in all, requirements will sooner or later change with high possibility that they won\u2019t fit into the architecture designed at the beginning.  This partially leads to a phenomenon known as technical debt . It is a metaphor coined by Ward Cunningham that describes sacrificing software quality and speeding its development by choosing faster and easier methods that at the same time aren\u2019t the best methods. Analogically to financial debt, technical debt should be repaid as soon as it is possible. Otherwise, developer will have to pay it back with interest. It usually means more hours spent on refactoring and bug fixing. Of course, there are critical moments, when you just have to make your software work by whatever method possible. Common causes leading to technical debt are, among others, business pressure and critical bugs.  Code Refactoring Criticism  There are people that approach code refactoring with reluctance. There are those that regard code refactoring as obsolete. They approach code refactoring as a waste of resources and the effect of insufficient upfront design. I beg to differ.  As much as it may seem boring, tiring and unneeded, I don't think that perfecting code should be considered a waste of resources. Especially in big, long-term projects. I also don't think that you can design every little element upfront. No amount of time spent on upfront design will catch all the problems that come up during actual development.  To refactor or not to refactor?  Not every piece of code has to be refactored. There are multiple cases of small projects or simple modules that are good as they are when they were finished and tested. Yet, software that is in constant development should be refactored from time to time. It's always better to refactor as soon as you discover that current design is no longer valid, but business pressure often leads us to postpone it.  In the end, the developer has to decide if her or his work needs code refactoring. Either way, thoroughly prepared and executed code refactoring can only bring good things to developers, partners, and end users.", "author": "jacek-chmielewski"}, {"slug": "never-leave-your-desk-unattended", "title": "Never leave your desk unattended...", "text": "Imagine starting just another ordinary day - getting up, eating breakfast, driving to work, sitting behind your desk and\u2026 wait a minute - something looks weird! Just like back in '90's when we were super-excited with first computers and AMIGA was a magic word that electrified all you classmates\u2026 OK, but why is it on my desk? The time I had fun swapping disks to play my favourite game is gone. It is a work time! What happened with my \"normal\" desk? :)  Yes, that was just another office prank of my colleagues that happened to find a way to optimize my workplace to keep me more productive. Very creative!  All these hardware comes from our company's museum where we gather unique pieces of technology from old times. If you have any stuff to join our collection, make sure you bring it to our office. We won't leave you with nothing in return.", "author": "robert-olejnik"}, {"slug": "meet-our-status", "title": "Meet our status board", "text": "We are excited to share with you details about our internal project called \"TEONITE Status\". It is placed in a central part of our office, displayed on a large LCD TV on one of our walls. You can't miss it!  Why we created it? Because running a software development company is like managing production in a factory - there is a lot of going on and you need to have a good view on what is happening  in different areas of the company, keep track of various metrics and make sure deadlines are met and projects are successfully delivered to clients.  We have many people on board with different sets of competence, various tools, applications & systems. We wanted to have control over that and make sure that each team member knows where we are.  One system to gather all  What we did is we designed a good-looking dashboard that combines data from our core systems that we use on a daily basis:   YouTrack ( http://jetbrains.com/youtrack/ ) - for managing our Agile production process  GitLab ( http://gitlab.org/ ) - for managing the code  Jenkins ( http://jenkins-ci.org/ ) - for building, testing and deploying the code  HipChat ( https://www.hipchat.com/ ) - our company\u2019s chat  Drum - ( https://github.com/teonite/drum ) - our own hacker news portal forked form DRUM project   So when you sit in our dining area drinking eating lunch or drinking fritz-cola you can have a glance on Status and be up-to-date with the operations and observe things are moving forward.  We really had fun creating that app and we have more ideas to come!  What's inside?  To sum up, just a few technical stuff on what is inside of Status.  Base technology:   Django ( https://www.djangoproject.com/ )  Django REST Framework  AngularJS ( http://angularjs.org )  and a lot of custom code for integration based on Celery ( http://celery.org )", "author": "marta-koziel"}, {"slug": "techfusion-an-event-for-doers-not-afraid-to-build-space-ships", "title": "TechFusion \u2013 an event for doers not afraid to build space ships", "text": "We are sitting in a room packed with tech people listening about the datebase in Google used to index the Internet (Bigtable). Marek Dopiera flew over to Szczecin from Ireland to share his knowledge and experience of working as a Site Reliability Engineer for the best search engine company in the world. He couldn\u2019t have revealed all the facts but gave a great insight about Big Table and challenges of managing and maintaining the heart of Google.  It was the fifth edition of TechFusion (17/10/2014), an event in Szczecin (Poland) where geeks and nerds from tech companies gather to enjoy amazing talks. But it is not only about top-notch technical insights but also as an inspiration for participants to connect and start something together.   \"We really want Tech Fusion to become something bigger. \n  A movement that people will be joining to cooperate, talk and start great initiatives\"  Robert Olejnik, TechFusion co-founder   Apart from Marek Dopiera, the event hosted two more speakers \u2013 Tomasz Oponowicz who talked about the latest streaming technologies and Jakub Lasota who gave an exciting speech about economical issues happening around us.  I asked Robert Olejnik, a co-founder of TechFusion three questions to sum-up what has already been achieved for the last few months around the idea of the meetup. He was happy to explain why the event was launched and why building a space ship is not such a big deal!  What kind of \"pain\" was behind starting TechFusion?  We couldn't find an event in Szczecin that was trully technical & geeky.  First of all, we solved our own problem as we really wanted to listen to great guys like Marek Dopiera working on one of the biggest systems in the world or find out how are Hollywood films made (TechFusion #1 - Krzysztof Grygowski presentation). We were curious how it works, what kind of software and hardware they work on, what sort of problems they have. We are obsessed with technology.  All the people coming to the event are hungry for great stuff that inspire them. When you were watching Jakub Lasota (Managing Partner at Zarzecki, Lasota & Partners) in action today talking about economy you could see he great enthusiasm and even better reception of the audience. He showed us interesting stats we had never been aware of and explained how things work in on financial markets. It was what we love to listen to, even if it had only little to do with what we work on a daily basis.  How did it all start?  I teamed up with Rafa\u0142 Malinowski and Krzysiek Kamrowski and we decided to start TechFusion. Rafa\u0142 had already been running a Facebook group - Szczecin Web Meetup's where people exchanged links, ideas, presentations, libraries. But it was time for a live event! We wanted people to connect, talk to each other and experience something extraordinary and I believe it is happening.  What is your plan for the next few months?  I would like more people to get involved in TechFusions and help us grow it for the benefit of all of us - from simple stuff like launching a new website to bringing stunning speakers on board.  We are a doer type of people - if I am eager to do something, I just do it. I know it sounds maybe a bit clich\u00e9 but you can achieve almost everything if you want. If somebody had told us there is a space ship to build, with our skills, it would have probably taken 100 years but it could have been done ;-)  I am happy that TechFusion has become a recognisable brand and different organisations are joining us to build a great technical community. We have already achieved more than we wanted, but our appetite just grows: more events, more great speakers with a unique voice, better presentations and more exciting topics that can expand our horizons.  Let\u2019s see where we are after another 5 events!  Pics from previous events", "author": "pawel-montwill"}, {"slug": "youtrack-intelij", "title": "Quick Tip: YouTrack & InteliJ IDEA / PyCharm", "text": "If your main development environment is InteliJ IDEa or PyCharm, you can speed up writing commit messages via integrating YouTrack task right into IDE.  Benefits?   Automatic task status change -> In Progress  Commit message including task id and title  Context change lists  +10 to awesomeness ;-)   How to? (ET: 2 min) :   Go to 'Tools -> Tasks & Contexts -> Configure Servers ...'  Click + > YouTrack  Enter your YouTrack server URL and your credentials  Copy your nice query from YouTrack  eg. 'project: {SuperCool Project} '   Select task (from toolbar) you want to work on   And that's it! Have fun ;-)", "author": "michal-gryczka"}, {"slug": "fixfusion-teonite-contributes-to-open-source-community", "title": "FixFusion - TEONITE contributes to Open Source community", "text": "A few weeks ago we wrote about our latest TechFusion event that is all about top-notch knowledge as an inspiration for participants not only to listen to great speakers but also to connect and inspire people to build new initiatives together.  FixFusion is a great example of that although it is not driven by the TechFusion team but it\u2019s a pure hacker initiative led by S\u0142awomir Pucia. Most people coming to the event build their business around open source software or at least use them as an important component in their projects.  So the idea with Fix fusion was to give something back to the community by meeting occasionally and contributing to selected open source platforms or creating something new. Each FixFusion event is held in different company\u2019s HQ, first one was @RedSky, second @LemonDemon and third will be hosted by us @TEONITE HQ.   Fixfusion #1 - Deployment Tool   During our first meeting in the Red Sky office we managed to release our Deployment tool that pushes Fabric to the next level by using it to handle operations on the remote server extended by functionalities that automate the whole deployment process ( read more about the tool ).  FixFusion #2 - TEONITE Django/Angular Support  The Polish proverb says: \u201cThe appetite grows while one eats\u201d and the same was with contributing to the Open Source community after the first FixFusion. So on the next meet-up in the Lemon Demon HQ we wanted to share a new solution from our portfolio of handy tools we use on a daily basis.  The problem: users using our applications want to easily and instantly get support - something like GetSatisfaction or UserVoice but for enterprise customers.  Solution: when we work with our clients we give them a little nifty widget that allow them to easily report any bugs or feature requests right out of the software we implement for them. They no longer need to write emails and we don\u2019t spend time asking them for their browsers\u2019 version or creating manually tasks in our ticketing system.   What they do is they use our Support widget which we integrate in all our applications to submit their comments/requests directly to our Project Management/Bug tracking software (in our case YouTrack). When submitting, our solution also automatically feeds all additional  information we need to solve the potential problem: username and its profile in the system, user-agent, referrer, IP, etc.  This way both a customer and TEONITE save their time - such a small piece of software but with great benefits for both parties!   When other guys during FixFusion saw our solution they already spotted what is missing - the screenshot capture functionality. In few days new pull requests started to arrive ;-)  This is how you use the synergy of having a few bright and open minds from different companies in one place. We really liked it!  Check it out if you use Django and/or Angular and improve the way you work with your clients!  https://github.com/teonite/Angular-Support   https://github.com/teonite/Django-Support  Seems we made a new tradition - publishing our OpenSource code during FixFusion events ;-) We already have a pipeline of new code ready to publish during next events.  More photos from meet-ups     All images by Slawomir Pucia", "author": "pawel-montwill"}, {"slug": "r-software-integrated-with-openpoland", "title": "R software integrated with OpenPoland", "text": "When we wrote a story from Robert\u2019s presentation on this year\u2019s InternetBeta we mentioned that during the conference Dr Kamil Wais declared his contribution to the Open Poland project. It was a great motivator for us as a new person believed in the idea and wanted to participate in the venture calling OpenPoland a groundbreaking project. He offered to create a library for an R software environment used by analysts and statisticians - and so he did!  Building a libary to connect R with OpenData  1. Coding  Just weeks after the event, Dr Kamil Wais developed a library for the R platform so that analysts can get an easy access to selected data through a few functions that automate communication between the tool and the Open Poland API.  2. Library on GitHub  Tha package has been submitted to GitHub:  R package for communication with OpenPoland.net API - a gate to open data in Poland \u201cThe OpenPoland package for R is a gate that leads you to the world of open data from Poland. With this package you can easily access hundreds milion of records in thousands of datasets generated and updated by institutions like Central Statistical Office of Poland.\u201d  https://github.com/kalimu/openPoland   3. Tutorial  To help users start using the tool, Dr Wais\u2019s published a tutorial on his blog that is an easy to understand a step-by-step instruction on how to start getting open data on the R software powered by OpenPoland. You can find all the necessary links and examples to kick-off:  http://www.wais.kamil.rzeszow.pl/pakiet-r-openpoland-tutorial/   4. OpenPoland in your web browser  If you are an analysts and you are not familiar with the R software package (or generally coding with API) but would like to have a quick and easy access to open data, you can use a web application that communicates with OpenPoland API and was also developed by Dr Wais:  http://gry.wsiz.pl:3838/samples/sample-apps/openPolandApp/   Promoting the usage of open data in Poland  Dr Kamil is aware that building tools is just a first step. But to make people use it you need to go far beyond that. That is why he became an advocate of open data by promoting their usage through seminars he organises. Building awareness is one of the main challenges when you popularise aa idea and want people to benefit from using new platforms.  During his presentations he focused on:   introduction to the topis  legal background  benefits of using open data  best practices from the US and the UK\ninitatives in Poland  experiences of obtain open data for commercial purposes  tools to obtain data (including analysis and visualisation).   And of course, the seminars couldn\u2019t omit the usage of OpenPoland and the R software!  Thank you!  We would like to warmly thank Kamil for his contribution and hard work. We work on OpenPoland in our \"spare time\" investing TEONITE\u2019s resources and it's great that the idea with open data is spreading by great people like Kamil!", "author": "michal-gryczka"}, {"slug": "keeping-your-local-docker-registry-clean", "title": "Quick Tip: Keeping your local Docker registry clean", "text": "Docker is a great tool, but when using it on a daily basis to build your environments - especially like we when we use Docker to build development, testing and production environments - your local registry tends to grow in terms of size (and number of images).  Here are two useful commands for keeping your registry clean:  Remove all not running containers  It's necessary to remove not used containers in order to be able to remove images that these containers used:  docker ps -a -q --filter \"status=exited\" | xargs docker rm  Remove all images that do not have a named repository  Most of the images that are built (by hand/fig) have repository names - if not, most probably they may be removed:  docker images | grep \"^<none>\" | awk '{print $3}' | xargs docker rmi", "author": "robert-olejnik"}, {"slug": "merry-christmas-and-a-happy-new-year-2015", "title": "Merry Christmas and Happy New Year 2015!", "text": "This year was really successfull for us. We hope that it was successfull for you as well. Have a beautiful and merry Christmas while being around your families and friends, and a happy New Year!  Our Christmas cards from previous years ;-)", "author": "robert-olejnik"}, {"slug": "three-companies-one-christmas-party", "title": "Our Christmas party", "text": "It was a great year for us with even better perspectives for 2015. We worked on many exciting projects, developed a lot of new tools and raised our workflow to the next level.  But this special time was about enjoying our companionship outside of work with the loved ones.  Apart from TEONITE we had inProjects and WellSERVED teams with us to celebrate Christmas time with their families.  And of course there is not Christmas party without a Santa Claus!", "author": "marta-koziel"}, {"slug": "quick-tip-debug-websocket-data-real-time", "title": "Quick Tip: debug WebSocket realtime data using your browser", "text": "When building realtime solutions using web technologies we often use WebSocket communication. There are several ways to debug WebSocket data, but we found this very useful during our development proces.  Displaying realtime WebSocket data using Chrome/Firefox/Safari Web Console  If you would like to see/debug realtime data from WebSocket very quickly, just open Chrome/Firefox/Safari Error console and use the following JavaScript code:  var ws = new WebSocket('ws://YourWebSocket.host:port/context')\nws.onmessage = function(data) {console.log(data)}  You should instantly get your server messages sent through the WebSocket.", "author": "robert-olejnik"}, {"slug": "building-a-bullet-proof-software-for-an-investment-company", "title": "Building a bullet-proof software for an investment company", "text": "What happens when a leading investment company in Poland needs a bullet-proof financial system for their clients? They look for an ambitious software company that can accept a challenge to build a real time financial platform, capable of operating on a wide spectrum of markets - OTC, Forex, Private Equity, Real Estates or Obligations.  That is how we joined ranks with Solution Partners , one of the most innovative investment companies in Europe!  After laying foundations for their business by building back office systems, the story goes on. Later this year we are going to launch a new robust platform with a state of the art architecture for our client.  We have a vision of how an investment software should look like and we will be happy to show more once it is ready. When working with Solution Partners we rely on our long term experience in building advanced financial systems.  \u201eWe always wanted to work with a software company that is ambitious to go beyond current standards and reliable to ensure stability of our business. After months of partnership with TEONITE we know they are this type of company.\u201d  - Tomasz Piwonski, CEO, Solution Partners  True art of software development  Building software has many challenges but when you implement real time financial solutions then it becomes a true art of software development.  Here are some challenges that we face during development:   planning & architecture is the key - that is why we have the best minds on board to outline software architecture, data structures, mark relations, bottlenecks, predict potential issues, plan use cases and make sure that at the end of the day the system is bullet-proof,  understanding your client\u2019s business - it doesn\u2019t happen often when you ask a developer to read a 500-pages book about financial markets, but it is the necessity - when you build complex systems you have to understand the realities your software will operate in because all the little details are important  high availability - with critical IT solutions microseconds matters that is why we make sure that the system is up and running 24/7 - reliable cloud hosting, strict SLA procedures, backups and redundancy systems in place allow us to keep the promise  bullet-proof testing - with real time systems in finance every comma and every line of the code has to be perfect - strict Quality Assurance processes, automated tests and result oriented teamwork, make us and our Client confident about outcomes.   Stay tuned for more news later this year!", "author": "robert-olejnik"}, {"slug": "5-guidelines-on-how-to-choose-a-software-company", "title": "5 guidelines on how to choose a software company", "text": "If you want to grow your company and beat competitors, sooner or later you will invest in IT solutions that will solve problems in a particular area of your business and improve operational processes.  This would require co-operation with a software company which becomes new experience for most of the business owners. That is why we gathered 5 points you should pay attention to when choosing a software house.  1. Look for partners, not subcontractors  Implementing new technology solutions in your business is a process that very often takes years. A software company you choose will co-operate closely with you covering more and more areas of your venture. For this reason, you need a company that understands your needs and thinks long-term when managing a relation with you.  Takeway: You need people that can get in your shoes and work for your success constantly improving the software. You need partners, not subcontractors.  2. Tell about your problems, expect solutions  IT solutions should  resolve problems you have and bring improvement to your business. To make sure it works that way, tell your potential partners about the pains you have and what goals you would like to achieve . It is their job to tell you how a system should work and what functionalities should be on board.  Takeway: A good software company will ask you a lot of detailed questions to make sure they covered all of the areas and that they understand your business. They should lead the way and be in charge of a project with your business objectives in mind.  3. Good software companies understand IT, great ones also understand business  You don\u2019t want tech people to be just blinded with a their code. You should find people that understand business realities and have a track record of systems that are fit for specific niches.  Takeway: Great software company will advise you different ways of solving your problems and will sometimes even disagree with you to convince you to look at a solution from a different perspective. They are experts and at the end of the day they are responsible for delivering your business objectives.  4. Quickly delivering results with Agile  When building a software you would definitely like to quickly see the results , monitor changes and have an ability to change the direction if requirements alter along the way. The way to achieve it is to use Agile software development methodology, like SCRUM.  Takaway: You need a Project Owner (PO) on your side that will monitor progress of work closely with a Project Manager (PM/Product Proxy) from a software company. With a Single Point Of Contact on your side you will be able to quickly examine results and react if changes to scope of work are required. Can your potential partners explain you how Agile works?  5. Expect only great communication  So once you have a Project Owner on your side and a Product Proxy on their side, then it comes time to ensuring that both parties communicate regularly. Professional software factories will always use an online software for managing a project to make sure that information exchange happens there instead of on e-mail only. Routine catch-ups are a must as well - either on the phone or in person.  Backlog Grooming meeting, that usually happens before each new sprint allows Project Owner on a client side to work with the development team and describe thoroughly requirements to various tasks from backlog. This ensures that at the end of each sprint new functionalities meet clients\u2019 expectations.  Takeway: Keeping-up a good relation and communicating often is necessary to receive a final product that you need and that will solve your problems. Ask a company you talk with about your long-term co-operation, what software for managing project they use and how they would communicate with you.   We will be honest with you - the above list describes how we work with our clients. We focus on quality over quantity to make sure our customers are 100% satisfied.  There are other great companies on the market that keep the same standard & values, but if you would like to work with us - get in touch .", "author": "robert-olejnik"}, {"slug": "the-greatest-services-in-the-world-that-run-on-python", "title": "The greatest services in the world run on Python", "text": "Most of our projects are written in Python. We were wondering what kind of famous online solutions are coded using this powerful language and found a quite interesting list of well known platforms.  Just to give you a flavour of Python usage, in 2011 at eBay/PayPal there were under 25 engineers coding in this language while three years later the number grew to 260 developers.  Enjoy going through the list!  DropBox  There is an interesting story behind this most popular cloud software. Back in 2006 when Drew Houston was pitching investors to receive funding for his start-up there were dozens of different cloud storage solutions on the market. How did Drew replied to this objection when a Venture Capital team asked for it?   You know how it ended up\u2026  Drew announced on the Dropbox Blog in 2012 that they hired Gudio van Rossum, the creator of Python programming language (smart move!) and he shared what is his favourite programming language:   \u201cDropbox is thrilled to welcome Guido, the creator of the Python programming language and a long-time friend of ours.\u201d  \u201cSeveral years earlier, Python became my favorite programming language because it had a balance of simplicity, flexibility, and elegance. These qualities of Python, and the community\u2019s work to support every major platform, let us write the code just once before running it everywhere. They have also influenced our greater design philosophy at Dropbox as we set out to build a simple product that brings your life together.\u201d   At TEONITE we use CoffeeScript as in many areas it has a similar language syntax to Python and it is quicker than JavaScript.  Dropbox has a similar approach: Dropbox dives into CoffeeScript    \u201cOur point is to forget CoffeeScript\u2019s influences for a minute, because it fixes so many of these syntactic problems and at least partially breaks free of JavaScript\u2019s slow evolution; even if you don\u2019t care for significant whitespace, we recommend CoffeeScript for so many other reasons. Disclaimer: we love Python, and it\u2019s Dropbox\u2019s primary language, so we\u2019re probably biased.\u201d   Google  Python is one of the 3 \"official languages\" at Google, alongside with Java and C++. Google uses Python for its mainframe foundation, as well as in addition to various apps that it runs in conjunction with the main site.   Peter Norvig, Research Director at Google said:   \"Python has been an important part of Google since the beginning, and remains so as the system grows and evolves. Today dozens of Google engineers use Python, and we're looking for more people with skills in this language.\"   Quora  In 2009 two former Facebook employees Adam D'Angelo and Charlie Cheever, founded Quora - a place where answers to all kind of questions can be found. They picked Python as their main programming language. What was their motivation behind this choice? Not surprisingly, they answered this question on Quora :   Spotify  In every tech company I know there is always somebody with Spotify opened on one of their screens to keep them going while they code, design, analyse or take care of social media marketing. Once you start using it, it is hard to imagine life without this online boombox. And by the way, they run on Python.   Spotify shares reasons behind using Python on their dev blog: How we use Python at Spotify    \u201cAt Spotify the main two places we use Python are backend services and data analysis. Python has a habit of turning up in other random places, as most of our developers are happy programming in it.\u201d  \u201cSpeed is a big focus for Spotify. Python fits well into this mindset, as it gets us big wins in speed of development.\u201d   Instagram  If you like watching your friends uploading #foodporn to Facebook then you definitely need to  sign up for Instragram. This photo-sharing & video-sharing social platform is built on Python mainly for its speed and flexiblity.   In What Powers Instagram: Hundreds of Instances, Dozens of Technologies Instagram engineers describe a few examples of Python usage including Task Queue & Push Notifications and Monitoring. They host Django framework on AWS.   \u201cFor Python error reporting, we use Sentry, an awesome open-source Django app written by the folks at Disqus. At any given time, we can sign-on and see what errors are happening across our system, in real time.\u201d   YouTube  We watch video clips on YouTube on a daily basis but most of us don\u2019t know it runs on Python. The foundation behind this language helped in integrating streaming video as well as \"like\" and \"embedding\" mechanisms.   Want to learn more about Python? Read 10 Myths of Enterprise Python on PayPal Engineering", "author": "robert-olejnik"}, {"slug": "grunt-vs-gulp-we-have-made-our-choice", "title": "Grunt vs. Gulp - we have made our choice", "text": "There is an ongoing discussion over the Internet which tool is better for task automation - is it Grunt or is it Gulp. I am sharing my thoughts on this topic below and indicate which one is my favourite.  Writing code  Grunt configuration is based on a JSON structure when describing tasks and options. Sometimes it is problematic for me to find where in the structure should I put certain parameters and what kind of options are available. An example from one of our projects:  copy: {\n    main: {\n      files: [\n        {\n          expand: true,\n          cwd: \u201asrc/lib/\u201a,\n          src: [\u201a**\u2019],\n          dest: \u201adist/lib/\u201a\n        }\n      ]\n    }\n  }  Gulp took a different approach as it is based on a \u201ecode-over-configuration\u201d philosophy where you define tasks by writing javascript or coffeescript code. So a similar task to the one above would look like this in Gulp:  gulp.task(\u201acopy\u2019, [\u201aclean\u2019], function() {\n  gulp.src(\u201esrc/lib/**/*\u201d)\n  .pipe(gulp.dest(\u201edist/lib\u201d))\n})  With such code I don\u2019t need to worry if \u201efiles\u201d list should be in section \u201emain\u201d, which option \u201eexpand\u201d is responsible for etc.  Point for: Gulp  The power of streams  Gulp, contrary to Grunt, uses node streams (just have a look at this part of the above code .pipe(gulp.dest(\u201edist/lib\u201d))). This way you can pass a result of one operation directly to another, for example: a complex coffeescript file can be sent to minification without a need to create temporary folders, as it happens in Grunt.  Point for: Gulp  Orchestration  Gulp uses orchestration to make use of parallel tasks execution and to minimise time needed for them to complete. A developer needs to only set relations of one task to the others and Gulp makes sure they run in correct order.  Point for: Gulp  Plugins  As Grunt has been available for many years it has a wide range of plugins that can be used. Gulp is a pretty new solution but it is quickly gaining traction and there is a growing community of developers using it on a daily basis.  Point for: Grunt  Verdict  Gulp vs Grunt: 3:1  In TEONITE we use Grunt for our older projects as with the new ones we automate tasks using Gulp. We keep fingers crossed for the future of this tool and believe that more developers will contribute to it.", "author": "jacek-chmielewski"}, {"slug": "how-to-set-up-rasberry-pi-in-your-office", "title": "How we use Rasberry PI in our office", "text": "The moment we saw Rasberry Pi we were thinking on how we can make use of it in our office. It came out that there are a few things Rasberry Pi 1 Model B+ can do pretty well and it was our geeky nature that pushed us to play around with it and see it in action.  What is Rasberry Pi?   \u201cThe Raspberry Pi is a low cost, credit-card sized computer that plugs into a computer monitor or TV, and uses a standard keyboard and mouse. It is a capable little device that enables people of all ages to explore computing, and to learn how to program in languages like Scratch and Python.  It\u2019s capable of doing everything you\u2019d expect a desktop computer to do, from browsing the internet and playing high-definition video, to making spreadsheets, word-processing, and playing games.\u201d   What to know more? Read here: https://www.raspberrypi.org/help/what-is-a-raspberry-pi/  How do we use it?  Boombox  Main feature of Rasberry Pi in our office is a media player to listen to the music. We have our company Spotify music lists that people can add their favourite songs to. They are run using SpotiMC, a dedicated OSMC Spotify plugin. It creates great work atmosphere in the office as songs play in the background and there are changing visualisations on the screen using OpenGL Spectrum.   Running Status board  A few months ago we wrote about one of our apps called Status board which displays a dashboard of what is currently happening inside of our software house. We used to have RasberryPI to display it on an LCD monitor so that everyone can see that. We are going to to launch a new version of it sometime in the future and we will be happy to share it.   Printing tasks for a Scrum Task Board  We used to work a on a proof-of-concept to see how \u201cInternet of things\u201d can be adopted to  software company daily operations.  When building application using agile methodology you have a Scrum Task Board with things to do in a current sprint. Normally you would write them on small pieces of paper and stick it to the board but we thought we can do better.  So we configured ticketing system in the way that it calls a webhook every time a task is moved from backlog to a certain sprint. This triggers REST API of a little app launched on Rasberry Pi that pushes this task to the labeling printer. Then a sticker pops-up and we can put it on our story wall.   If you would like to dive in to the details about the gear and software that it runs on, read below.  What is inside?  Our model is called Pi1 Model B+ which was replaced in the meantime by Rasberry Pi 2 Model B with faster CPU and more RAM.   Rasberry Pi 1 Model B+ has a CPU and 256MB RAM and it communicates with an outside world through the following interfaces:   HDMI - we plugged in a 23\u201d LCD monitor to it  4 USB 2.0 ports - minature keyboard and mouse is enough to have a full control over the device  Ethernet - connecting Rasberry to the global network  Audio - with speakers we cover the whole office with chilling sounds  Mini-SD card slot - little computer requires little hard drive  5V micro USB power supply   Software running on Rasberry Pi  To make use of the beauty of this mini-computer we used Open Source Media Center (OSMC) which is a free and open source system based on Linux. It lets you play back media from your local network, attach storage and connect to the Internet.  OSMC has everything you need when you start your journey with Rasberry:   it is free  it takes minutes to install it  there is an App Store to get more software on board  updates are easy  it support most of the media formats  it has a growing community of users and contributors   And by the way, it looks great. Just have a look.", "author": "kamil-chudy"}, {"slug": "polityka-partners-with-teonite", "title": "Polityka partners with TEONITE - core system development", "text": "In the recent years we have been observing how the internet & mobile revolution brought changes to the publishing industry. It has become a serious challenge for magazines as they need to quickly adjust to the trends and changes in the behaviours of their clients.  \" We use an approach of one universal platform that will support an automatization of multi-device content distribution. The platform needs to be flexible, fitting our editorial routines and providing ultimate experience for our readers. They still value our content but there are different ways how and when they want to read, listen and watch it.   That is why we have decided to introduce a tailor-made application for smartphones and tablets to provide our readers with full mobile experience and staying in touch with POLITYKA. \" - Joanna Chmielecka - Digital Publishing Editor, Polityka  Our Partner\u2019s goal - taking electronic publishing to the next level  In order to meet client\u2019s goals we proposed a  dedicated digital platform, a new back-end system and mobile applications:   Business logic - we focused on designing mechanisms needed to manage and distribute digital content - from content purchasing mechanisms and billing system   to embedded audio player.  Microservices architecture - this approach to software building allowed us to deliver independent back-end (admin) and front-end (mobile, web) systems that communicate through APIs. This modular structure gives us and the client full flexibility in future development as content and data may be delivered to any system with API including new marketplaces. \nIn the first stage we have introduced a mobile app for and iPhone and iPad (iOS), later we have implemented the Windows 10 multi platform application (Windows 10 PC, Windows 10 phone & tablet). Microservices architecture gives us the comfort of efficiently plugging in new interfaces.  Integrations - new digital publishing platform had to connect with various systems inside the company and with the third party solutions:  Polityka Cyfrowa online platform - allowing thousands of paid subscribers of POLITYKA to log-in using the same access data to the website and mobile apps while making sure that they access content which they paid for.\ninternal Polityka publishing platform - mechanisms to upload content to the system so that it can be consumed on mobile apps.  Apple iTunes Connect - to allow clients to buy content directly from their iOS apps.  Delivering new mobile apps:  iPhone/iPad app - choosing magazines to buy or download and embedded player allows you to play the audio content   Windows 10 (mobile/desktop/tablet) - choosing magazines to buy or download and embedded player allows you to play the audio content    The result  \u201cFor the last years we have been successfully selling electronic versions of POLITYKA magazines through various e-kiosks and our iPad app. But we needed universal system that would support our processes of content distribution.   To handle new demands we have decided to build the whole back-end system from the scratch. Integration with our Polityka Cyfrowa system was a must as we had thousands of users accessing our online content through this channel.  TEONITE rose to the challenge - I\u2019m satisfied with our new product launch and looking forward to our long-term cooperation.\u201d - Marek Rafa\u0142owicz - Project Owner at Polityka  As we wrote in our previous article, \u201e5 guidelines on how to choose a software company\u201d when building tech solutions you should look for partners instead of subcontractors. Polityka was aware of that and they have decided to go for a long-term co-operation with us to secure proper development of their electronic content platform for upcoming years.  We have set a goal to improve user experience as new technologies emerge and to make sure that we can improve the way users interact with the content.  3 tips for building mobile solutions  There are a few tips we would like to share with you that we have learned from this case:  Investing in continuous deployment workflow  It took us long months of building our software development processes based on Docker containers infrastructure - which was a fundament to our continuous delivery platform. What does it mean to the client? Lower costs in a time & material model and better tested software that can be deployed efficiently.  Load & stress testing  Test automation and handling edge cases is a standard for us but what surprised us the most in this project were load and stress testing that we introduced. We thought that our apps were rock-solid and in fact they were. But with these types of QA procedures in place we detected flaws in the server environment configuration and could quickly react to it.  Your app may be great but you need to make sure that with thousands of users on board the whole platform can handle the load.  Content and users migration to the new system  If you are building a new back-end system from scratch, you need to make sure that you have a solid step-by-step plan to migrate all of the clients from the current solution to the new platform. So the goal for us was not only to deliver better mobile apps but also to make sure that the transition to the new system goes smoothly. Users logging-in to the app on the next day after the launch just as they did on the previous day was also part of the experience we took care of.", "author": "robert-olejnik"}, {"slug": "nginx-docker-virtualhosts", "title": "Multiple static sites hosting with Docker and NGINX", "text": "Docker is a great platform which we use at large to simplify and automate development & provisioning processes.  Sometimes though it's not easy to find quick solutions to common problems you face in production systems. That's why we've developed several patterns/custom solutions to make it painless and fun.  Below is one of out short solutions:  Problem  Hosting multiple static sites with NGINX + Docker.  Solution  Our custom NGINX image:  https://github.com/teonite/docker-nginx-dynamic-sites  docker-nginx-dynamic-sites is a simple solution to have one NGINX docker/container instance for multiple domains (virtual hosts) dynamically. For more info go to the project's github page .", "author": "robert-olejnik"}, {"slug": "teonite-member-docker-partner-program", "title": "TEONITE now a member of the Docker Partner Program", "text": "TEONITE is now the official partner of Docker! We've just joined Docker Partner Program.   \"Docker provides a completely open platform for developing distributed applications. All our solutions are build, run, and deployed at scale using Docker.\n  We plan to open source our in-house solutions supporting our agile development process which are based on Docker, meanwhile we want to support the community by showing how great Docker tools are and officaly partnering with Docker.\" - Robert Olejnik, TEONITE CEO", "author": "robert-olejnik"}, {"slug": "designing-a-content-based-platform-a-general-insight-into-techsoup-pl", "title": "Designing a Content-Based Platform \u2013 A General Insight into TechSoup.pl", "text": "Today, many content-based companies live up to the \u2018the more the better\u2019 maxim. However, it is not the same for each and every company or enterprise. In fact, there are many tools other than publishing content that answers the problem of expanding a business influence on the market.  TechSoup since 1987 has served as a bridge between the social sector and the technology products, services, funding, and knowledge, that are essential for improving lives. TechSoup\u2019s mission is to build a dynamic bridge that enables civil society organizations and changemakers around the world to gain effective access to the resources they need to design and implement technology solutions for a more equitable planet. TechSoup runs software donation programs all over the world partnering with many corporate partners, such as Adobe, Cisco, Microsoft or Google. Products of these partners are offered through TechSoup to non-profit organizations in 236 countries and territories around the world. Being the most popular platform for NGOs, TechSoup has many NGO partners and branches across the globe including the Polish partner \u2013 TechSoup Poland .  TechSoup.pl started with an idea: they wanted to expand its business capabilities and influence the voluntary sector by providing a regular, technology focused content. After a few workshops and detailed business analysis with the TechSoup team, we decided to build a platform oriented around user\u2019s easy access to different types of content, like articles, events\u2019 descriptions, tutorials and products  What makes our platform unique?  What makes our platform one of a kind and differs it from a typical CMS are the mechanisms to freely link, relate, promote and suggest content such as offered products and services.  In other words, we built this system on the edge of the database and an advanced search engine that features the possible control over the search results and suggestions, as well as content correlation across the platform.  The advanced search engine mentioned above is the Elasticsearch search engine . The main strong points of Elasticsearch are the real-time data insight with adjustable filtering and near real-time full-text search with ratings of given elements. Moreover, Elasticsearch searches through full text, and not only titles or tags added by the publisher. The database elements may be linked together. This gives the TechSoup platform user a full and thorough searching capability. Additionally, the potential client will also see items, such as blog posts, tutorials, and products related to the phrase or keyword they seek.  What does it mean for TechSoup? Better opinion in the eyes of their users, possible rating upgrade of important products and content to place it in the preferred position in the search results, as well as deep, real-time insight into platform database and statistics.  Going mobile without an App \u2013 The matter of responsivity  Let\u2019s be honest, a responsive web design is nowadays a standard procedure. Thus, we naturally decided to make TechSoup design responsive as well. Thanks to the responsive web design, TechSoup platform users can enjoy the same elements with the desktop version and any of their mobile devices. Of course, each device has slightly different layout adjusted to the given device (including IPhone and IPad) settings and requirements, but the content and possible interaction stay the same. This is a big fund-saver for TechSoup and a considerable time saver for the platform user as they don\u2019t need to download a separate app for each device.  Another characteristic of the design that is worth mentioning is modularity. The modules we implemented feature blog posts, tutorials, products list as well as a calendar with important dates. Basically, a user of the TechSoup platform has easy access to all relevant data and content in a simple and clear manner. We also equipped it with direct links to TechSoup\u2019s social media pages and an easily accessible subscription form to their newsletter.  How did we do it?  To make the partnership with TechSoup easy and rewarding for both sides, and to provide a workflow without obstructions, we were basing on our favorite technologies and frameworks. Next to already mentioned Elasticsearch, we used Python-based Django server framework (with Django REST framework ). This gave us and our partners more time to think about the project itself, instead of spending numerous hours on building servers from scratch. Likewise, we used AngularJS. It\u2019s usability and the fact that we specialize in AngularJS makes it a perfect tool for such undertaking. For our deployment and testing needs, we used Docker. This gave us the opportunity to build, ship and test the TechSoup platform without worrying about environmental inconsistence.  The partnership with TechSoup was based on mutual respect to each other\u2019s ideas and design suggestions. We were getting regular feedback from the TechSoup team and we gave them access to each stage of development. Thanks to this, working together with TechSoup was effective, fast and without unnecessary misunderstandings.   Our main goal is to support NGOs and social institutions in the effective use of innovative technology to raise NGOs efficiency to the next level. We all need to work better and faster to build a clear and consistent social community of NGOs, social activists, and IT specialists to create a good, self-supporting environment. Because of our technological focus, we decided to partner up with TEONITE to build a reliable and user-friendly platform. Thanks to mutual respect and good teamwork, our goals and ideas were molded into the TechSoup.pl platform.  Karolina Dudzic, TechSoup Poland Product Owner   The result  Together with our partner, we came to an idea - instead of building a simple CMS, let\u2019s make a complex, but user-friendly, accessible system better suited to resolving set business goals. In the end, the TEONITE/TechSoup partnership bears fruit in the form of a complete platform that was a perfect answer for their business goals.", "author": "robert-olejnik"}, {"slug": "angular-drf-auth", "title": "Angular authentication (and authorization) based on Django REST Framework tokens", "text": "TL;DR  Authenticate AngularJS app with Django ( REST framework ) backend using Token Based Authentication written in Coffee Script .  Code: https://github.com/teonite/Angular-DRF-Auth  Intro  At the time there was no module like this available - so we've created one. We love simplicity! We've put much effort in making this module as slim and easy to use as possible.  Core Features  Angular-DRF-Auth is based on Token Authentication in Django REST Framework with the following features:   simple front-end template with a log-in form  redirection to the log-in form if unlogged user tries to enter an application  authorisation rights based on assigned roles  defining if particular webpage should require authentication (or authorization)  Angular UI-Router support  hide/display selected elements using hasPermission and hasPermissionToObject directives depending on granted permissions   Use scenario  1) A user wants to enter restricted page.  2) Angular-DRF-Auth checks if there is cookie 'token' for that site, if not it redirects to /#/login at this site.  /#/login url is configured to be managed by LoginCtrl which is a part of AngularAuth library.  3) LoginCtrl posts user and password to backend's url - /api-token-auth that is managed by Django REST Framework. If username and password are correct, api-token-auth returns the token in the response.  4) Token is stored as a cookie and common authentication http header is set to Token and the token value.  5) Next there is another backend call to /check-auth which is any url managed by Django REST Framework which returns user in the response.  6) The user is set to angular $rootScope to session object. If the token cookie exists, angular auth calls /check-auth to get the user and set it to the scope, it happens always when the page is refreshed.  7) Angular auth provides the directive has-permission-to-object which can be used to show/hide page elements based on permissions of the user groups.  Basic usage  <div has-permission-to-object=\"write_project\" user=\"user\" object=\"project\"/>  User is an object which is returned by /check-auth url, project is an example name which can be anything you want to check user access on it - It has to have 'visibility' property which is the table of the object with permission property:  project.visibility = [{permission: 1}, {permission: 2}]  That means that user has to have at least one of the group permission with id=1 or id=2 to have an access to the project object.  Has-permission-to-object directive deals also well with the angular-chosen select components and is able to enable/disable them. The directive can also 'negate' the permission check, it can be done with '!' sign, f.e.  <div has-permission-to-object=\"!write_project\" user=\"user\" object=\"project\"/>  That means that this div will be displayed only for users that don't have write_project group permission.  Webapp configuration using angular ui router  .config(function ($stateProvider, $urlRouterProvider) {\n    // redirect to project list on /\n    $urlRouterProvider.when('', '/check');\n\n    // define states\n    $stateProvider\n        .state('check', {\n            url: '/check',\n        })\n        .state('login', {\n            url: '/login',\n            templateUrl: 'common/templates/login.html',\n            controller: 'LoginCtrl',\n            resolve: {\n            }\n        })\n}  Backend configuration that uses Django REST Framework  url(r'^api-token-auth/', 'rest_framework.authtoken.views.obtain_auth_token'),\nurl(r'^check-auth/', CheckAuthView.as_view()),\n\nclass CheckAuthView(generics.views.APIView):\n    def get(self, request, *args, **kwargs):\n        return Response(UserWithFullGroupsSerializer(request.user).data)", "author": "michal-gryczka"}, {"slug": "d3-satellite-chart-library", "title": "D3 Satellite Chart Library", "text": "Today, we give you our D3 Satellite Chart Library . This chart started as a part of financial data analysis project and was specifically made for presenting indicators together with their values in intuitive, interesting and readable way.  Strong point of this chart\u2019s design is the approach to indicators. They are categorized on three levels. Each of them corresponds (stays in the orbit) to the indicator one level above. All indicators and their values are summarized and processed to provide main grade of these indicators in the center of the chart. This way it is clear which constituents influence which indicators and how strong the influence is.  When looking on the Satellite Chart from design perspective, resemblance to heavenly bodies (sun, planets and moons) becomes clear.  You can get the D3 Satellite Chart Library at our open source lab, Evolution Chamber . You can also see the live preview here .", "author": "janusz-gadek"}, {"slug": "jupyter-notebook-django-access", "title": "Jupyter Notebook in our Development Process", "text": "Over the past years, Jupyter Notebook gained much interest from the programming community and is considered one of the most useful and popular tools you can currently find. We\u2019d like to share with you our opinion of Jupyter Notebook and how exactly we used it in our development process.  What is Jupyter Notebook?  Jupyter Notebook (earlier known as IPython Notebook) is an interactive computing environment which allows you to work on notebook documents that can contain live code, explanatory text, equations and multimedia resources like audio and video. Jupyter can and very often is used for scientific purposes as well as data transformation, numerical simulations, and machine learning. It supports over 40 programming languages, especially ones used in data science like Python and R.  For us, Jupyter Notebook is a really great tool. Code cells and easy way of creating data visualizations inside notebook are really helpful.  Live Access to Django APP through Jupyter Notebook  Django is one of our favorite web frameworks. Some of you probably know this, but there is a good library called django-extensions which adds a couple of useful elements. One of those extensions is django shell_plus which can be run as a notebook. This gives us some new options for working with Django, all of them based on Jupyter Notebook characteristics and features. For example, we can easily extract django orm objects, apply any operations we need and save them back to database.  This became especially useful during development of one of our data analysis platforms. We had an API deployed in production server. Sometimes we had to work on complex computations off-schedule which were normally automated and ran during nights or weekends. Without Jupyter we had to go through Rancher (awesome docker orchestration platform we use), run console on app container, initiate the shell_plus and only then we had access to Django objects. Moreover, if we had to do the same computation again we had to repeat all the steps again, previous work was lost in terminal history. Not very effective.  What we did to overcome this issue was as simple as running  manage.py shell_plus --notebook  on app container and exposing Jupyter port so that we could connect to it remotely (no worries, we secured it too).  We could \u201cstore\u201d all of the necessary scripts in our notebook, run them and add new ones. And all of it had to be written just once. Additionally, Jupyter\u2019s code cell architecture gave us an  opportunity to just run a single, secluded script without running the whole set.  Possible future implementation  Theoretically, we could make a set of different notebooks divided thematically; for example one for operations on projects, one responsible for portfolios etc. We also consider creating a Docker image which would, by default, add the option to work through Jupyter Notebook to each Django project.", "author": "jacek-chmielewski"}, {"slug": "evolution-chamber", "title": "Enter the Evolution Chamber", "text": "We proudly present you the Evolution Chamber \u2013 our contribution to open source.  When you take a look at the state of modern IT industry, it is clear that open source resources are commonly used in any possible situation. Almost every IT company and team of developers use open source as a base for their software. At least, we do. This is why we\u2019ve created the Evolution Chamber \u2013 to return the \u2018debt\u2019 we took through many years of our business.  Evolution Chamber is a hub for all open source projects, modules, and tools we have released in past as well as for all of the future developments. Evolution Chamber\u2019s design was made by Krzysztof Kamrowski . If you are a geek, you may find it interesting, that we have developed a character system used to generate names of released projects. Why make separate logo for each entry, when you can use an algorithm that picks three numbers and code them in the font inspired by DNA helix and hexagrams?   We\u2019ll be publishing new projects regularly , but not without thorough testing; quality comes first. We have already planned another dozen or so modules to be released in near future. Lastly, we sincerely welcome you to Evolution Chamber and invite you to share your thoughts, opinions, and ideas with us.", "author": "robert-olejnik"}, {"slug": "how-to-keep-track-of-multiple-projects-part1", "title": "How to Keep Track of Multiple Projects Part 1", "text": "TEONITE is an agile development team and each one of us is specialized in different field of information technology. We\u2019re mainly a service company, so it\u2019s natural we take on many projects simultaneously. One of the most important and most difficult things to do is to keep track of multiple projects at the same time . And that is my job.  Sprint 101  To ensure stable, accurate and fast development we divide projects into sprints. A sprint is a set period of time during which a number of processes occur. Each sprint starts with a meeting with a product owner to plan what parts from full product requirements should be done during that particular sprint. Then, we work according to the schedule. At the end of each sprint, we sum up all work that was done. In case of any failures, we analyze the cause to not repeat mistakes. Any tasks that, for any reason, weren\u2019t completed (lack of assets, lack of upfront design) will be discussed over with the product owner at the beginning of next sprint.  In theory, shorter sprints work better . They trigger more meetings with product owner, thus we better understand requirements and product owner has full insight into project. Short sprints also save time (and money) in case product owner changes his mind about a particular feature.  By far, sprints are the most productive type of workflow management in projects that aren\u2019t fully designed but are rather an idea or concept that takes shape during development. In that case, we mostly do weekly sprints \u2013 they are short enough that they don\u2019t change midway and are long enough to push the project forward and have any meaningful feedback.  Monitoring and management with multi-level agile board  Our weapon of choice to monitor and schedule all project/team data is YouTrack .  Our usual setting of swimlanes includes:  - Epic for all general ideas that yet have to be divided into features\n- Feature for tasks that are defined and have to be implemented, \n- Bug for bug reports and fixes, \n- Tasks for general tasks and subtask that are neither feature implementations nor bugs.  We also have one extra swimlane, Change Request (CR) in which product owner can add tasks or comments with any changes he has in mind.  Change Request swimlane is particularly helpful in case of project budget review. Let\u2019s imagine a project which has requirements for 15 features, so the budget was calculated accordingly to the initial requirements. After 10 weeks we have 5 implemented features out of 15 planned, plus 10 features that came during the development process due to product owner\u2019s change requests. All in all, we have implemented 15 features and we\u2019re already closing the budget. To avoid such situation, all our clients and partners engaged in given project can monitor the state of development through shared YouTrack\u2019s multi-level agile boards.  Tweaking never stops  So we use YouTrack and multi-level agile boards. Are we satisfied? Sure. Do we stop seeking new ways to improve our workflow? Certainly not. We never stop tweaking. There are always elements that can be adjusted and optimized for each single project. For us, YouTrack is the best tool for this kind of job (at least for now). Everyone knows what has to be done and by who. All issues and bugs are instantly reported. And all this on a single page.  In the next part of this article we will take a closer look at other levels of YouTrack's multi-level agile boards. Follow us on Twitter to know about more interesting articles about project management in IT.", "author": "michal-gryczka"}, {"slug": "kickstarter-we-are-a-backer", "title": "We're a silver sponsor of new Django REST Framework", "text": "We became a Silver Sponsor of the new version of Django REST framework, which is our main framework-of-choice for REST APIs in Django. Always happy to contribute!  All project details you can find on:  Kickstarting Django REST framework 3", "author": "robert-olejnik"}, {"slug": "openpoland-net-public-data", "title": "OpenPoland - new quality in public data", "text": "OpenPoland is currently the largest collection of public data available through the API in Poland. We have now more than 138 million records! public data open data Open Poland API  OpenPoland was born out of frustration!  For the last few years we have been working on several projects that required large amounts of public data (eg. Monitor Rozwoju, Moja Polis and others). We noticed that the access to public data is a common problem of all organisations, companies and local governments that have ambitions to build systems supporting decisions based on accurate and current data.  We hit the wall several times - when there was no API to plugin to when trying to obtain data from a various government entities, when data was not up-to-date or was totally defragmented.  What happened if we had to gather data from 40 or 50 administration units from all over the country? We had to write letters to each of them to receive data on CDs in many formats and standards. Imagine putting everything together, matching the same type of information from different files, indexing and setting logic to what we have collected. Thousands of hours of mundane work.  So others can save their time!  We decided we need to change this frustrating situation so we invested another months of hard work so others don\u2019t have to and built OpenPoland.net. It was worth it! We are asked about how we financed the project and our response is simple - we put in our own money in this project because we thought it was worth it. We can all benefit from open data.  3 things you need to know about OpenPoland   API that is easy to use - we put emphasis on ease of data retrieval and use of the API itself. The website contains search mechanism to automatically generate queries in different systems to improve access to the data. API allows for direct data integration in any analytical system or programming environment, which can vastly speed up the analysis process and open new opportunities.  Data integrity - we take care of keeping integrity across all data assets, which is a great challenge when it comes to public data in Poland.  Consistent and always up to date - OpenPoland is at the moment the only repository of statistical data updated on a daily basis. The purpose of the API is to provide wholesale mode data in the form closest to the sources. Therefore data is available in specific blocks to facilitate the assessment of the completeness and quality of data. With one query to the API, you can retrieve the data of the selected index in a given year at the commune level or for all levels above the commune (district, sub-region, province, region).    How can you benefit from OpenPoland?  OpenPoland is a platform that gives you access to current public data via API. The system contains data from the Local Data Bank of Central Statistical Office of Poland and soon will include also other data sources.  OpenPoland could become a key element in the process of building:   data analysis systems  mobile applications based on public data  government portals  data visualization solutions    Who is it for?  The project was designed for:   entities involved in the analysis of data and creation of analytical tools;  IT companies (eg building statistical systems, data warehouses);  all companies, institutions, private entities whose goal is to create a system using public data and which don\u2019t have acces to the data;  entities that build system and want to save time and effort.   Use of API OpenPoland saves time during the preparation of applications and systems as:   sparing in updating and validating data  allows instant and fast access to metadata  automates the process of downloading selected data   Case study - obtaining data regarding companies that invested in innovation  Step 0 Log in to OpenPoland and get API token.  Step 1 Go to OpenPoland.net and find your subject:  Option A: Using data search engine:  Option B: using metadata browser:   Step 2 Generate an example query using a button on a list or in your browser metadata widget:   Step 3 Copy the code snippet and play with it!    You can find working code from the example above in our sandbox repository at GitHub ( https://github.com/teonite/OpenPoland-sandbox )  Get in touch with us  If you don\u2019t know how to use the API or how to integrate OpenPoland with your system - ([get in touch] http://teonite.com/contact.html )!", "author": "michal-gryczka"}, {"slug": "our-develoment-tool-opensourced", "title": "Our deployment tool opensourced!", "text": "During the first FixFusion in May 2014 we have released one of our Internal systems - a TEONITE Deployment tool for deployment, provisioning and database migration to the OpenSource world. Many great products come from solving your own problem. The same happened with this project. We welcome the fact that the first pull requests appeared soon after FixFusion!  We pushed Fabric to the next level!  We have tried various deployment tools and since Python is our main choice when it comes to programing language we mostly used Fabric.  But as always, we wanted more out of that and decided to build our own solution that meets expectations of our developers and fits the way we work.  So we we pushed Fabric to the next level by using it handle operations on the remote server but we added functionalities that automate the whole deployment process for us :   full control of every step - process preparation, files selection (copy, remove, keep), unpacking  setting procedures to be triggered before, during and after deployment  predefined deployment model for all projects and a dedicated configuration per project  check if necessary virtualenv exists and required packages are installed  restart processes using Supervisor  mail notification after deployment   Our first Open Source release  As we use TEONITE Development in almost all of our projects and were super-excited to contribute it to the Open Source community as many areas of our business is based on the open code. Deployment is our first step in this direction and we hope that next FixFusion events will allow developers worldwide to benefit from using other projects we have developed so far.  Typical deployment flow  Folder structure  remote_dir\n|-deploy_dir\n|   |-20130411_212959\n|   |-20130411_213213\n|   |-20130412_181014\n|   |-current -> 20130412_181014\n|   |-previous -> 20130411_213213\n|-migration_dir\n|-upload_dir\n|-dump_file'  Deployment process   Test remote server & check if connection to remote server is possible.  Execute pre-deploy commands  Get sources & if local git repository is found, it will be pulled, else will be cloned.  Archive sources  Upload sources to remote server  Extract source to target subfolder  Switch current/previous links  Copy config files  Run post-deploy commands  Documentation   Full documentation can be found here:  https://deployment.readthedocs.org/en/latest/   https://github.com/teonite/deployment/", "author": "krzysztof-krzysztofik"}, {"slug": "geek-week-teonite-europython-2014", "title": "EuroPython 2014 - spending 6 days with Python enthusiasts in Berlin", "text": "EuroPython isn't just a conference - it is a place where you meet people for the first time and you already speak the same language. The Python language.  We are happy that after three years EuroPython moved from Florence to Berlin so we could get there in less than 2 hours.   The truth is that with 100 presentations and 4 workshops everyday you will quickly stumble upon a speaker that will make you say \"Can I really do it that way? I haven't never thought it can be done like that...\".   It is just full of how-tos, tricks & hacks that will save you tons of time & energy when solving daily programming challanges.  We learnt how Disqus is using Django as the basis of their SOA, took part in a Q&A session with ElasticSearch authors and talked with the dh-virtualenv author from Spotify about the best way of shipping apps (dh-virtualenv? Docker? - we have our solution to that problem, soon a blog post to come!).  After a week of such intense knowledge pack you come back to the office and you don't know where to start!      All of our photos from the event could be found on Facebook - Eyropython gallery   More details on an event's website: EuroPython 2014  Satellite Event: PyData   Along the EuroPython 2014 was a satllite event PyData 2014 . You can see on-line presentation and other:  https://www.youtube.com/user/PyDataTV", "author": "pawel-montwill"}, {"slug": "openpoland-interbeta2014", "title": "Robert on InternetBeta 2014 talking about OpenPoland", "text": "InternetBeta is an event you can't miss if you want to be up-to-date with the latest online solutions and if you plan to meet people running the most exciting internet projects in Poland.  This year Robert Olejnik, our CEO was among 70 speakers from around the world coming from various industries - sociologists, political scientists, representatives of interactive agencies, advertising, owners and managers of the largest sites, application developers investors, marketers.  Robert shared a stage with Jan Herbst from Stocznia foundation ( http://stocznia.org.pl ) and they both had a unique opportunity to present challenges regarding open data issues in Poland. The presentation was based on our project called OpenPoland.net - which is a solution that delivers access to the Polish government statistics via API.  Who benefits from open data?  Questions that were asked after the presentation show that few people are familiar with the open data topic. It will change as more and more people will benefit from access to the data - analytics, sociologists, business consultants, rating companies, local governments and councils as well as organisations that build strategies.  4 challenges when working with open data in Poland  OpenPoland was born out of frustration to bring new quality to open data in Poland. During the presentation we emphasised challenges we had to face when working with public data for the last few years. Just to name a few:\n- Dealing with large amount of data - for example, \u201cnewlyweds\u201d indicator with all the dimensions gives you 134 millions records \n- Government IT systems in Poland are in bad condition - no API interfaces available, lack of synchronisation between different government ministries and organisations, poor system architecture\n- Making sure that data is up-to-date and if not, managing this situation in relations to other areas\n- A lot of data had to be manually imported to the system through API  Dr Kamil Wais declared his contribution to the project  Sharing details about our groundbreaking project was a great reward for us but the satisfaction was even bigger when one of the conference attendees declared his contribution to OpenPoland. Dr Kamil Wais offered to create a library for R software environment used by analysts and statisticians. It will allow its users to get an easy access to selected data through a few functions that will automate communication between a software and Open Poland API (more information about this as the work is ongoing - will come soon on our blog).  We are more than pleased with this support as it will open doors for a wide group of users to easily benefit from OpenPoland.  We strongly encourage you to join the ranks and grow the largest bank of public data in Poland and make it available for others so that we can all build greater solutions.  Read more in our post about the OpenPoland project .", "author": "pawel-montwill"}]